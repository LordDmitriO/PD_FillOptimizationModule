"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
"""

import re
import os
import json
import random as rd
import tempfile
import pymorphy3
import time
from selenium import webdriver as wd
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup as BS

import config
from .humanization import Humanization
from .recaptcha_solver import ReCaptchaSolver


class BaseSearcher:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö —Å–µ–∞—Ä—á–µ—Ä–æ–≤ —Å –æ–±—â–∏–º–∏ —É—Ç–∏–ª–∏—Ç–∞–º–∏"""

    def __init__(self, browser, humanizer, log_callback=None):
        self.browser = browser
        self.humanizer = humanizer
        self.log_callback = log_callback

    def log(self, message):
        """–í—ã–≤–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ª–æ–≥"""
        if self.log_callback:
            self.log_callback(message)
        else:
            print(message)

    @staticmethod
    def get_genitive_case_pymorphy(org_name):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞–¥–µ–∂–∞ —á–µ—Ä–µ–∑ pymorphy3"""
        if not org_name:
            return org_name

        morph = pymorphy3.MorphAnalyzer()

        words = org_name.split()
        genitive_words = []

        for word in words:
            if word.startswith(("¬´", '"', '"')) or word.endswith(("¬ª", '"', '"')):
                genitive_words.append(word)
            else:
                clean_word = word.strip(".,;:!?")
                punct = word[len(clean_word) :] if len(word) > len(clean_word) else ""

                parsed = morph.parse(clean_word)[0]
                genitive_form = parsed.inflect({"gent"})

                if genitive_form:
                    genitive_words.append(
                        genitive_form.word.capitalize()
                        if clean_word[0].isupper()
                        else genitive_form.word + punct
                    )
                else:
                    genitive_words.append(word)

        return " ".join(genitive_words)

    @staticmethod
    def remove_quotes_for_search(text):
        """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ —Ç–∏–ø—ã –∫–∞–≤—ã—á–µ–∫ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞"""
        if not text:
            return text
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Ç–∏–ø—ã –∫–∞–≤—ã—á–µ–∫: –æ–±—ã—á–Ω—ã–µ, —Ç–∏–ø–æ–≥—Ä–∞—Ñ—Å–∫–∏–µ, –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ
        return re.sub(r'["\'¬´¬ª""]', '', text).strip()

    @staticmethod
    def normalize_organization_name(name):
        """
        –ü—Ä–∏–≤–æ–¥–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É:
        - –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã
        - –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ —Å–æ —Å—Ç—Ä–æ—á–Ω–æ–π
        - –¢–µ–∫—Å—Ç –≤ –∫–∞–≤—ã—á–∫–∞—Ö —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –ø–µ—Ä–≤–æ–π –±—É–∫–≤—ã
        """
        if not name:
            return name

        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö (–ª—é–±—ã–µ —Ç–∏–ø—ã –∫–∞–≤—ã—á–µ–∫)
        quote_pattern = r'[¬´"\'"][^¬´¬ª"\'""]+[¬ª"\'""]'

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –∫–∞–≤—ã—á–∫–∞–º–∏ –∏ –∏—Ö –ø–æ–∑–∏—Ü–∏–∏
        matches = list(re.finditer(quote_pattern, name))

        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–∞–≤—ã—á–µ–∫, –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É
        if not matches:
            return name.capitalize()

        result = []
        last_end = 0

        for i, match in enumerate(matches):
            start, end = match.span()

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –î–û –∫–∞–≤—ã—á–µ–∫
            before_text = name[last_end:start]
            if before_text:
                words = before_text.split()
                normalized_words = []
                for j, word in enumerate(words):
                    # –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –≤—Å–µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è - —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π
                    if last_end == 0 and j == 0:
                        normalized_words.append(word.capitalize())
                    else:
                        normalized_words.append(word.lower())

                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–±–µ–ª –≤ –∫–æ–Ω—Ü–µ –µ—Å–ª–∏ –æ–Ω –±—ã–ª
                normalized_before = " ".join(normalized_words)
                if before_text.endswith(" "):
                    normalized_before += " "
                result.append(normalized_before)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –í –∫–∞–≤—ã—á–∫–∞—Ö
            quoted_text = match.group()
            opening_quote = quoted_text[0]
            closing_quote = quoted_text[-1]
            inner_text = quoted_text[1:-1]

            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É: –ø–µ—Ä–≤–∞—è –±—É–∫–≤–∞ –∑–∞–≥–ª–∞–≤–Ω–∞—è, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ—á–Ω—ã–µ
            normalized_inner = inner_text.capitalize()
            result.append(f"{opening_quote}{normalized_inner}{closing_quote}")

            last_end = end

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞—Ç–æ–∫ —Ç–µ–∫—Å—Ç–∞ –ü–û–°–õ–ï –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∫–∞–≤—ã—á–µ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if last_end < len(name):
            after_text = name[last_end:]
            words = after_text.split()
            normalized_words = [word.lower() for word in words]
            result.append(" ".join(normalized_words))

        return "".join(result)


class RusProfileSearcher(BaseSearcher):
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –≤ RusProfile"""

    def __init__(
        self, browser, humanizer, log_callback=None, use_recaptcha_solver=False, recaptcha_solver=None
    ):
        super().__init__(browser, humanizer, log_callback)
        self.use_recaptcha_solver = use_recaptcha_solver
        self.recaptcha_solver = recaptcha_solver
        self._std_rules = None

    def _handle_rusprofile_captcha(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–∞–ø—á–∏ –Ω–∞ RusProfile –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –µ—ë.
        """
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            # –ï—Å–ª–∏ –µ—Å—Ç—å - —ç—Ç–æ –Ω–µ –∫–∞–ø—á–∞, –∞ –ø—Ä–æ—Å—Ç–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
                has_results = (
                    self.browser.find_elements(By.ID, "clip_name-long")
                    or self.browser.find_elements(By.CLASS_NAME, "list-element__title")
                    or self.browser.find_elements(By.CLASS_NAME, "company-name")
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
                body = self.browser.find_element(By.TAG_NAME, "body")
                page_text = body.text.lower()
                has_no_results_message = (
                    "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ" in page_text
                    or "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π" in page_text
                    or "–ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–º—è–≥—á–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã" in page_text
                )
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ" - —ç—Ç–æ –Ω–µ –∫–∞–ø—á–∞
                if has_results or has_no_results_message:
                    return
            except Exception:
                pass  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥–∞–ª—å—à–µ

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–∞–ø—á–∏ (–±–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ iframe —Å recaptcha
                recaptcha_iframes = self.browser.find_elements(
                    By.CSS_SELECTOR, "iframe[src*='recaptcha'], iframe[title*='reCAPTCHA']"
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–æ—Ä–º—ã –∫–∞–ø—á–∏
                captcha_forms = self.browser.find_elements(
                    By.CSS_SELECTOR, "form[id*='captcha'], form[class*='captcha']"
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –æ –∫–∞–ø—á–µ/—Ä–æ–±–æ—Ç–µ
                body = self.browser.find_element(By.TAG_NAME, "body")
                page_text = body.text.lower()
                page_source_lower = self.browser.page_source.lower()
                
                # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –∫–∞–ø—á—É
                captcha_phrases = [
                    "–≤—ã —Ä–æ–±–æ—Ç",
                    "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç",
                    "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ, —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç",
                    "–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–æ–±–æ—Ç–∞",
                    "–≤—ã –ø–æ—Ö–æ–∂–∏ –Ω–∞ —Ä–æ–±–æ—Ç–∞",
                ]
                
                has_captcha_text = any(phrase in page_text for phrase in captcha_phrases)
                has_recaptcha_widget = "g-recaptcha" in page_source_lower or "recaptcha/api.js" in page_source_lower
                
                # –ö–∞–ø—á–∞ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏:
                # 1. –ï—Å—Ç—å iframe —Å recaptcha –ò–õ–ò
                # 2. –ï—Å—Ç—å —Ñ–æ—Ä–º–∞ –∫–∞–ø—á–∏ –ò–õ–ò
                # 3. –ï—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç –æ –∫–∞–ø—á–µ –ò –µ—Å—Ç—å –≤–∏–¥–∂–µ—Ç recaptcha
                is_captcha = (
                    len(recaptcha_iframes) > 0
                    or len(captcha_forms) > 0
                    or (has_captcha_text and has_recaptcha_widget)
                )
                
                if not is_captcha:
                    return  # –ö–∞–ø—á–∏ –Ω–µ—Ç, –≤—ã—Ö–æ–¥–∏–º
                    
            except Exception:
                # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É –∫–∞–∫ fallback
                try:
                    body = self.browser.find_element(By.TAG_NAME, "body")
                    page_text = body.text.lower()
                    page_source_lower = self.browser.page_source.lower()
                    
                    # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∏ "—Ä–æ–±–æ—Ç" –≤ —Ç–µ–∫—Å—Ç–µ, –∏ recaptcha –≤ –∫–æ–¥–µ
                    if "—Ä–æ–±–æ—Ç" in page_text and ("g-recaptcha" in page_source_lower or "recaptcha/api.js" in page_source_lower):
                        pass  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–∞–ø—á–∏
                    else:
                        return  # –ù–µ –∫–∞–ø—á–∞
                except Exception:
                    return  # –ù–µ –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –∫–∞–ø—á–∏ –Ω–µ—Ç

            # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞ - –∫–∞–ø—á–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞
            self.log("\n" + "!" * 60)
            self.log("üõë –û–ë–ù–ê–†–£–ñ–ï–ù–ê –ö–ê–ü–ß–ê RUSPROFILE! üõë")

            # –ù–û–í–û–ï: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∫–∞–ø—á–∏
            if self.use_recaptcha_solver and self.recaptcha_solver:
                self.log("ü§ñ –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è —á–µ—Ä–µ–∑ ruCaptcha...")

                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–µ—à–∏—Ç—å
                if self.recaptcha_solver.solve_recaptcha_v2(self.browser):
                    self.log("üîÑ –†–µ—à–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ. –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–æ—Ä–º—É...")

                    # –ë–ª–æ–∫ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ä–º—ã –ø–æ—Å–ª–µ –≤–≤–æ–¥–∞ —Ç–æ–∫–µ–Ω–∞
                    try:
                        # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–Ω–æ–ø–∫—É —Å–∞–±–º–∏—Ç–∞ (—ç—Ç–æ –Ω–∞–¥–µ–∂–Ω–µ–µ —á–µ–º –ø—Ä–æ—Å—Ç–æ form.submit)
                        submit_btn = self.browser.find_elements(
                            By.CSS_SELECTOR,
                            "button[type='submit'], input[type='submit']",
                        )
                        if submit_btn:
                            submit_btn[0].click()
                            self.log("üñ±Ô∏è –ù–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏.")
                        else:
                            # 2. –ï—Å–ª–∏ –∫–Ω–æ–ø–∫–∏ –Ω–µ—Ç, —Å–∞–±–º–∏—Ç–∏–º —Ñ–æ—Ä–º—É
                            self.browser.execute_script(
                                """
                                var forms = document.getElementsByTagName('form');
                                if (forms.length > 0) {
                                    forms[0].submit();
                                }
                            """
                            )
                            self.log("üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ —Ñ–æ—Ä–º–∞ —á–µ—Ä–µ–∑ JS.")

                        self.humanizer.human_like_wait(3.0)

                    except Exception as e:
                        self.log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–æ—Ä–º—ã: {e}")
                        self.log("üîÑ –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É...")
                        self.browser.refresh()
                        self.humanizer.human_like_wait(3.0)

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    try:
                        page_text_after = self.browser.find_element(
                            By.TAG_NAME, "body"
                        ).text
                        if "—Ä–æ–±–æ—Ç" not in page_text_after.lower():
                            self.log("‚úÖ –ö–∞–ø—á–∞ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–π–¥–µ–Ω–∞!")
                            self.log("!" * 60 + "\n")
                            return
                    except:
                        pass

                    self.log("‚ö†Ô∏è –ö–∞–ø—á–∞ –≤—Å–µ –µ—â–µ –Ω–∞ –º–µ—Å—Ç–µ –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏ —Ä–µ—à–µ–Ω–∏—è.")
                else:
                    self.log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç ruCaptcha.")
            else:
                self.log("‚ÑπÔ∏è –ê–≤—Ç–æ-—Ä–µ—à–µ–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ –∏–ª–∏ —Å–æ–ª–≤–µ—Ä –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")

            self.log("üëâ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–µ—à–∏—Ç–µ –∫–∞–ø—á—É –í–†–£–ß–ù–£–Æ –≤ –±—Ä–∞—É–∑–µ—Ä–µ.")
            self.log("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –∫–∞–ø—á–∏...")
            self.log("!" * 60 + "\n")

            # –¶–∏–∫–ª –æ–∂–∏–¥–∞–Ω–∏—è
            while True:
                try:
                    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —ç–ª–µ–º–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ–π –≤—ã–¥–∞—á–∏ - –≤—ã—Ö–æ–¥–∏–º
                    if (
                        self.browser.find_elements(By.ID, "clip_name-long")
                        or self.browser.find_elements(
                            By.CLASS_NAME, "list-element__title"
                        )
                        or self.browser.find_elements(By.CLASS_NAME, "company-name")
                    ):  # –î–æ–±–∞–≤–∏–ª –µ—â–µ –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫

                        self.log("‚úÖ –ö–∞–ø—á–∞ –ø—Ä–æ–π–¥–µ–Ω–∞ (–æ–±–Ω–∞—Ä—É–∂–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç)!")
                        self.humanizer.human_like_wait(2.0)
                        break

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞
                    if not self.browser.window_handles:
                        break

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –∏—Å—á–µ–∑ –ª–∏ —Ç–µ–∫—Å—Ç –ø—Ä–æ —Ä–æ–±–æ—Ç–∞
                    body_text = self.browser.find_element(By.TAG_NAME, "body").text
                    if (
                        "—Ä–æ–±–æ—Ç" not in body_text.lower()
                        and "recaptcha" not in self.browser.page_source
                    ):
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –º—ã –Ω–µ –Ω–∞ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                        self.log("‚úÖ –¢–µ–∫—Å—Ç –∫–∞–ø—á–∏ –∏—Å—á–µ–∑. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º.")
                        time.sleep(2)
                        break

                except Exception:
                    pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–æ–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ–∫–∞ –∂–¥–µ–º

                time.sleep(2)

        except Exception as e:
            self.log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –ª–æ–≥–∏–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–ø—á–∏: {e}")

    def _load_standardization_rules(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∞–≤–∏–ª —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏"""
        if self._std_rules is not None:
            return self._std_rules

        try:
            rules_path = os.path.join(
                os.path.dirname(__file__), "..", "..", "standardization_rules.json"
            )
            rules_path = os.path.abspath(rules_path)
            with open(rules_path, "r", encoding="utf-8") as f:
                self._std_rules = json.load(f)
                return self._std_rules
        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å standardization_rules.json: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∞–≤–∏–ª
            self._std_rules = {"abbreviations": {}, "type_synonyms": {}}
            return self._std_rules

    def _expand_abbreviations_in_text(self, text):
        """–†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ—Ç –≤—Å–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã –≤ —Ç–µ–∫—Å—Ç–µ, –Ω–æ –ù–ï –∑–∞–º–µ–Ω—è–µ—Ç –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã –≤–Ω—É—Ç—Ä–∏ –∫–∞–≤—ã—á–µ–∫"""
        if not text:
            return text
        
        rules = self._load_standardization_rules()
        result = text
        abbreviations = rules.get("abbreviations", {})
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö, —á—Ç–æ–±—ã –Ω–µ –∑–∞–º–µ–Ω—è—Ç—å –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã –≤–Ω—É—Ç—Ä–∏ –Ω–∏—Ö
        quote_pattern = r'["\'¬´¬ª][^"\']+["\'¬ª]'
        quoted_parts = []
        for match in re.finditer(quote_pattern, result):
            quoted_parts.append((match.start(), match.end(), match.group()))
        
        # –°–æ–∑–¥–∞–µ–º –≤–µ—Ä—Å–∏—é —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –∫–∞–≤—ã—á–µ–∫ –¥–ª—è –∑–∞–º–µ–Ω—ã
        text_without_quotes = result
        placeholders = {}
        for i, (start, end, quoted_text) in enumerate(quoted_parts):
            placeholder = f"__QUOTE_PLACEHOLDER_{i}__"
            placeholders[placeholder] = quoted_text
            text_without_quotes = text_without_quotes[:start] + placeholder + text_without_quotes[end:]
        
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–º–µ–Ω—è–µ–º –û–ü–§ (–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ-–ø—Ä–∞–≤–æ–≤—ã–µ —Ñ–æ—Ä–º—ã) –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–ª–∏–Ω–µ (–æ—Ç –¥–ª–∏–Ω–Ω—ã—Ö –∫ –∫–æ—Ä–æ—Ç–∫–∏–º), —á—Ç–æ–±—ã —Å–Ω–∞—á–∞–ª–∞ –∑–∞–º–µ–Ω—è—Ç—å —Å–æ—Å—Ç–∞–≤–Ω—ã–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã
        opf_abbreviations = sorted(
            [(abbr, full_form) for abbr, full_form in abbreviations.items() 
             if abbr in ["–ê–ù–û–û", "–ê–ù–û", "–ú–ë–û–£", "–ì–ë–û–£", "–ú–ê–û–£", "–ú–ö–û–£", "–ì–ö–û–£", 
                        "–ß–û–£", "–ù–ß–û–£", "–§–ì–ë–û–£", "–§–ì–ê–û–£", "–ì–ê–û–£", "–ì–ë–ü–û–£", "–ì–ê–ü–û–£"]],
            key=lambda x: len(x[0]),
            reverse=True
        )
        
        for abbr, full_form in opf_abbreviations:
            # –ò—â–µ–º –û–ü–§ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ (—Ç–æ–ª—å–∫–æ –≤–Ω–µ –∫–∞–≤—ã—á–µ–∫)
            pattern = r'^' + re.escape(abbr) + r'\s+'
            if re.search(pattern, text_without_quotes, re.IGNORECASE):
                text_without_quotes = re.sub(pattern, full_form + " ", text_without_quotes, flags=re.IGNORECASE)
                break  # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é –û–ü–§ –≤ –Ω–∞—á–∞–ª–µ
        
        # –ó–∞—Ç–µ–º –∑–∞–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã (—Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–ª–∏–Ω–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∑–∞–º–µ–Ω—ã)
        # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã (1-2 —Å–∏–º–≤–æ–ª–∞), –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å —á–∞—Å—Ç—å—é –¥—Ä—É–≥–∏—Ö —Å–ª–æ–≤
        other_abbreviations = sorted(
            [(abbr, full_form) for abbr, full_form in abbreviations.items() 
             if abbr not in ["–ê–ù–û–û", "–ê–ù–û", "–ú–ë–û–£", "–ì–ë–û–£", "–ú–ê–û–£", "–ú–ö–û–£", "–ì–ö–û–£", 
                            "–ß–û–£", "–ù–ß–û–£", "–§–ì–ë–û–£", "–§–ì–ê–û–£", "–ì–ê–û–£", "–ì–ë–ü–û–£", "–ì–ê–ü–û–£"]
             and len(abbr) >= 3],  # –¢–æ–ª—å–∫–æ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã –¥–ª–∏–Ω–æ–π 3+ —Å–∏–º–≤–æ–ª–∞
            key=lambda x: len(x[0]),
            reverse=True
        )
        
        for abbr, full_form in other_abbreviations:
            # –ò—â–µ–º –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—É –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ (—Ç–æ–ª—å–∫–æ –≤–Ω–µ –∫–∞–≤—ã—á–µ–∫)
            pattern = r'\b' + re.escape(abbr) + r'\b'
            if re.search(pattern, text_without_quotes, re.IGNORECASE):
                text_without_quotes = re.sub(pattern, full_form, text_without_quotes, flags=re.IGNORECASE)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –æ–±—Ä–∞—Ç–Ω–æ
        result = text_without_quotes
        for placeholder, quoted_text in placeholders.items():
            result = result.replace(placeholder, quoted_text)
        
        return result

    def _is_educational_keyword(self, text):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"""
        if not text:
            return False
        
        text_lower = text.lower()
        rules = self._load_standardization_rules()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã (–∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞)
        for abbr in rules.get("abbreviations", {}).keys():
            # –ò—â–µ–º –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—É –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ
            pattern = r'\b' + re.escape(abbr.lower()) + r'\b'
            if re.search(pattern, text_lower):
                return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        edu_keywords = [
            "—à–∫–æ–ª–∞", "—Å–æ—à", "–ª–∏—Ü–µ–π", "–≥–∏–º–Ω–∞–∑–∏—è", "–∫–æ–ª–ª–µ–¥–∂", "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç",
            "–∏–Ω—Å—Ç–∏—Ç—É—Ç", "—É—á–∏–ª–∏—â–µ", "–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω", "—É—á—Ä–µ–∂–¥–µ–Ω–∏–µ", "–¥–µ—Ç—Å–∫–∏–π —Å–∞–¥",
            "–¥–æ—É", "–¥–≤–æ—Ä–µ—Ü —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞", "–¥–æ–º —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞", "—Ü–µ–Ω—Ç—Ä –¥–µ—Ç—Å–∫–æ–≥–æ",
            "—Ü–µ–Ω—Ç—Ä —Ä–∞–∑–≤–∏—Ç–∏—è", "—Ü–µ–Ω—Ç—Ä –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è"
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        for keyword in edu_keywords:
            if keyword in text_lower:
                return True
        
        return False

    def _has_unique_words(self, text, original_text=None):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ (–Ω–µ —Ç–æ–ª—å–∫–æ –æ–±—â–∏–µ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã)"""
        if not text:
            return False
        
        text_lower = text.lower()
        
        # –û–±—â–∏–µ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ (–∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ —Ñ–∞–π–ª–∞)
        rules = self._load_standardization_rules()
        common_edu_words = set(rules.get("common_words", []))
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        words = set(re.findall(r'\b[–ê-–Ø–Å–∞-—è—ë]{3,}\b', text_lower))
        
        # –£–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞
        unique_words = words - common_edu_words
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ - —ç—Ç–æ —Ö–æ—Ä–æ—à–æ
        if unique_words:
            return True
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ª–æ–≤–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö - —ç—Ç–æ —Ç–æ–∂–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ
        if re.search(r'["\'¬´¬ª][^"\']+["\'¬ª]', text):
            return True
        
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
        if original_text:
            original_words = set(re.findall(r'\b[–ê-–Ø–Å–∞-—è—ë]{3,}\b', original_text.lower()))
            original_unique = original_words - common_edu_words
            if original_unique and unique_words:
                # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ - —ç—Ç–æ —Ö–æ—Ä–æ—à–æ
                if original_unique.intersection(unique_words):
                    return True
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ - —ç—Ç–æ —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
        return False

    def _validate_organization_result(self, org_name, result, check_keyword_match=True):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –Ω–∞–π–¥–µ–Ω–Ω–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
        
        Args:
            org_name: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –ò–ù–ù)
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
            check_keyword_match: –ü—Ä–æ–≤–µ—Ä—è—Ç—å –ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (False –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –ò–ù–ù)
        """
        if not result.get("found") or not result.get("name"):
            return False
        
        found_name = result["name"].lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–π–¥–µ–Ω–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è - –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ —É—á—Ä–µ–∂–¥–µ–Ω–∏–µ
        if not self._is_educational_keyword(found_name):
            self.log(f"  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º —É—á—Ä–µ–∂–¥–µ–Ω–∏–µ–º: {found_name[:70]}...")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        negative_keywords = [
            "–ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
            "–ª–∏–∫–≤–∏–¥–∞—Ç–æ—Ä",
            "–ª–∏–∫–≤–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –∫–æ–º–∏—Å—Å–∏–∏",
            "–ø—Ä–∏–∑–Ω–∞–Ω–∏—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π",
            "—Ç–µ–∞—Ç—Ä",
            "—Ä–µ–ª–∏–≥–∏–æ–∑–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è",
            "–ø—Ä–∏—Ö–æ–¥",
            "—Ö—Ä–∞–º",
            "—Ü–µ—Ä–∫–æ–≤—å",
            "—Ç–æ–≤–∞—Ä–∏—â–µ—Å—Ç–≤–æ",
            "—Å–Ω—Ç",
            "—Ç—Å–Ω",
        ]
        
        for neg_keyword in negative_keywords:
            if neg_keyword in found_name:
                self.log(f"  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ '{neg_keyword}': {found_name[:70]}...")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        if check_keyword_match and org_name:
            original_name = org_name.lower()
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
            original_words = set(re.findall(r'\b[–ê-–Ø–Å–∞-—è—ë]{3,}\b', original_name))
            found_words = set(re.findall(r'\b[–ê-–Ø–Å–∞-—è—ë]{3,}\b', found_name))
            
            # –ò—Å–∫–ª—é—á–∞–µ–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞ (–∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ —Ñ–∞–π–ª–∞)
            rules = self._load_standardization_rules()
            common_words = set(rules.get("common_words", []))
            original_words -= common_words
            found_words -= common_words
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è (—ç—Ç–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω—ã–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞)
            quoted_words_original = set()
            quoted_matches = re.findall(r'["\'¬´¬ª]([^"\']+)["\'¬ª]', original_name)
            for quoted_text in quoted_matches:
                quoted_words_original.update(re.findall(r'\b[–ê-–Ø–Å–∞-—è—ë]{3,}\b', quoted_text.lower()))
            quoted_words_original -= common_words
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
            if original_words and found_words:
                intersection = original_words.intersection(found_words)
                if not intersection:
                    self.log(f"  ‚ö†Ô∏è –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –º–µ–∂–¥—É '{org_name[:50]}...' –∏ '{found_name[:50]}...'")
                    return False
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ª–æ–≤–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö, –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å
                if quoted_words_original:
                    quoted_intersection = quoted_words_original.intersection(found_words)
                    if not quoted_intersection:
                        self.log(f"  ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –∏–∑ –∫–∞–≤—ã—á–µ–∫ '{org_name[:50]}...' –≤ '{found_name[:50]}...'")
                        return False
        
        return True

    def generate_search_variants(self, org_name):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä"""
        variants = []
        rules = self._load_standardization_rules()

        # 1. –ü–ï–†–í–´–ô –í–ê–†–ò–ê–ù–¢: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä–∞–º–∏
        expanded_original = self._expand_abbreviations_in_text(org_name)
        if expanded_original != org_name:
            variants.append(expanded_original)

        # 2. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–±–µ–∑ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏)
        variants.append(org_name)

        # 3. –£–±–∏—Ä–∞–µ–º –≥–æ—Ä–æ–¥ –≤ –∫–æ–Ω—Ü–µ (–ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ –ø—Ä–æ–±–µ–ª–∞)
        # "–ê–ù–û–û –õ–∏—Ü–µ–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç –ë–∞–ª–∞—à–∏—Ö–∞" -> "–ê–ù–û–û –õ–∏—Ü–µ–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç"
        without_city = re.sub(
            r"[,\s]+(?:–≥\.?\s*)?[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+–æ–±–ª\.?)?$", "", org_name
        )
        if without_city != org_name:
            variants.append(without_city.strip())
            # –° —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π
            expanded_without_city = self._expand_abbreviations_in_text(without_city.strip())
            if expanded_without_city != without_city.strip() and expanded_without_city not in variants:
                variants.append(expanded_without_city)

        # 4. –£–±–∏—Ä–∞–µ–º –≤—Å—ë –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∫–∞–≤—ã—á–µ–∫
        # '–ê–ù–û–û "–õ–∏—Ü–µ–π "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç" –ë–∞–ª–∞—à–∏—Ö–∞' -> '–ê–ù–û–û "–õ–∏—Ü–µ–π "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç"'
        quote_match = re.search(r'(.+["\'])\s+[–ê-–Ø–Å]', org_name)
        if quote_match:
            variant = quote_match.group(1).strip()
            variants.append(variant)
            # –° —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π
            expanded_variant = self._expand_abbreviations_in_text(variant)
            if expanded_variant != variant and expanded_variant not in variants:
                variants.append(expanded_variant)

        # 5. –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –≤ –∫–∞–≤—ã—á–∫–∞—Ö (–ù–û —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)
        # '"–õ–∏—Ü–µ–π "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç"' –∏–ª–∏ "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç"
        quoted = re.findall(r'["\']([^"\']+)["\']', org_name)
        if quoted:
            # –ë–µ—Ä–µ–º —Å–∞–º—É—é –¥–ª–∏–Ω–Ω—É—é —Ü–∏—Ç–∞—Ç—É
            longest_quote = max(quoted, key=len)
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            if self._is_educational_keyword(longest_quote):
                variants.append(longest_quote)
                # –° —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π
                expanded_quote = self._expand_abbreviations_in_text(longest_quote)
                if expanded_quote != longest_quote and expanded_quote not in variants:
                    variants.append(expanded_quote)

        # 6. –£–±–∏—Ä–∞–µ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ-–ø—Ä–∞–≤–æ–≤—É—é —Ñ–æ—Ä–º—É –≤ –Ω–∞—á–∞–ª–µ
        # "–ê–ù–û–û –õ–∏—Ü–µ–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç" -> "–õ–∏—Ü–µ–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç"
        without_opf = re.sub(
            r'^(?:–û–û–û|–ó–ê–û|–û–ê–û|–ê–û|–ò–ü|–§–ì–ë–û–£|–ú–ë–û–£|–ê–ù–û–û|–ù–û–£|–ì–û–£|–ú–û–£|–ê–ù–û)\s+["\']?', "", org_name
        )
        if without_opf != org_name:
            without_opf_clean = without_opf.strip()
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            if self._has_unique_words(without_opf_clean, org_name):
                variants.append(without_opf_clean)
                # –° —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π
                expanded_without_opf = self._expand_abbreviations_in_text(without_opf_clean)
                if expanded_without_opf != without_opf_clean and expanded_without_opf not in variants:
                    if self._has_unique_words(expanded_without_opf, org_name):
                        variants.append(expanded_without_opf)

        # 7. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ - –æ–±—ã—á–Ω–æ –≤ –∫–∞–≤—ã—á–∫–∞—Ö –∏–ª–∏ –ø–æ—Å–ª–µ –û–ü–§)
        # –ù–∞—Ö–æ–¥–∏–º –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –±–µ–∑ –û–ü–§ –∏ –≥–æ—Ä–æ–¥–∞
        core_name = re.sub(
            r"^(?:–û–û–û|–ó–ê–û|–û–ê–û|–ê–û|–ò–ü|–§–ì–ë–û–£|–ú–ë–û–£|–ê–ù–û–û|–ù–û–£|–ì–û–£|–ú–û–£|–ê–ù–û)\s+", "", org_name
        )
        core_name = re.sub(
            r"[,\s]+(?:–≥\.?\s*)?[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+–æ–±–ª\.?)?$", "", core_name
        )
        if core_name and core_name != org_name:
            core_name_clean = core_name.strip()
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            if self._has_unique_words(core_name_clean, org_name):
                variants.append(core_name_clean)
                # –° —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π
                expanded_core = self._expand_abbreviations_in_text(core_name_clean)
                if expanded_core != core_name_clean and expanded_core not in variants:
                    if self._has_unique_words(expanded_core, org_name):
                        variants.append(expanded_core)

        # 8. –¢–æ–ª—å–∫–æ —Å–ª–æ–≤–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö –±–µ–∑ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤ (–ù–û —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞)
        clean_quoted = re.findall(r'["\']([–ê-–Ø–Å–∞-—è—ë\s]+)["\']', org_name)
        for cq in clean_quoted:
            cq_clean = cq.strip()
            if cq_clean and cq_clean not in variants:
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                if self._is_educational_keyword(cq_clean):
                    variants.append(cq_clean)
                    # –° —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–æ–π
                    expanded_cq = self._expand_abbreviations_in_text(cq_clean)
                    if expanded_cq != cq_clean and expanded_cq not in variants:
                        variants.append(expanded_cq)

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        seen = set()
        unique_variants = []
        for v in variants:
            v_clean = v.strip()
            if v_clean and v_clean not in seen and len(v_clean) > 3:
                seen.add(v_clean)
                unique_variants.append(v_clean)

        return unique_variants

    def search(self, org_name=None, inn=None):
        """–ü–æ–∏—Å–∫ –≤ RusProfile –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏–ª–∏ –ò–ù–ù —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        result = {
            "found": False,
            "address": "",
            "postal_code": "",
        }

        try:
            main_url = "https://www.rusprofile.ru"

            if inn:
                # –ü–æ–∏—Å–∫ –ø–æ –ò–ù–ù (–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å)
                return self._search_by_inn(main_url, inn, result)
            else:
                # –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Å –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏
                return self._search_by_name_with_variants(main_url, org_name, result)

        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}")

        return result

    def _search_by_name_with_variants(self, main_url, org_name, result):
        """–ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏"""
        variants = self.generate_search_variants(org_name)
        original_org_name = org_name  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏

        self.log(f"  üîÑ –ü–æ–ø—Ä–æ–±—É—é {len(variants)} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–æ–∏—Å–∫–∞:")
        for i, variant in enumerate(variants, 1):
            self.log(f"     {i}. ¬´{variant}¬ª")

        for attempt, variant in enumerate(variants, 1):
            self.log(f"  üîç –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{len(variants)}: ¬´{variant}¬ª")

            # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–¥ –∫–∞–∂–¥–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
            result["found"] = False
            result["name"] = ""
            result["address"] = ""
            result["postal_code"] = ""
            result["inn"] = ""
            result["ogrn"] = ""
            result["name_genitive"] = ""

            try:
                # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
                self.browser.get(main_url + "/search-advanced")
                self.humanizer.human_like_wait(rd.uniform(0.5, 1.0))

                self._handle_rusprofile_captcha()

                try:
                    search = self.humanizer.human_like_wait_for_element(
                        self.browser, (By.ID, "advanced-search-query"), 10
                    )
                    if not search:
                        # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                        result["found"] = False
                        result["name"] = ""
                        result["address"] = ""
                        result["postal_code"] = ""
                        result["inn"] = ""
                        result["ogrn"] = ""
                        result["name_genitive"] = ""
                        continue

                    search.clear()
                    # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
                    search_variant = self.remove_quotes_for_search(variant)
                    self.humanizer.human_like_type(self.browser, search, search_variant)
                    self.humanizer.random_mouse_movement(self.browser, search)
                    search.send_keys(Keys.ENTER)
                    self.humanizer.human_like_wait(rd.uniform(1.0, 2.0))

                    self._handle_rusprofile_captcha()
                except TimeoutException:
                    # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                    result["found"] = False
                    result["name"] = ""
                    result["address"] = ""
                    result["postal_code"] = ""
                    result["inn"] = ""
                    result["ogrn"] = ""
                    result["name_genitive"] = ""
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                try:
                    search_result = self.humanizer.human_like_wait_for_element(
                        self.browser, (By.CLASS_NAME, "list-element__title"), 5
                    )
                    if not search_result:
                        self.log(f"     ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                        result["found"] = False
                        result["name"] = ""
                        result["address"] = ""
                        result["postal_code"] = ""
                        result["inn"] = ""
                        result["ogrn"] = ""
                        result["name_genitive"] = ""
                        continue
                except TimeoutException:
                    self.log(f"     ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                    result["found"] = False
                    result["name"] = ""
                    result["address"] = ""
                    result["postal_code"] = ""
                    result["inn"] = ""
                    result["ogrn"] = ""
                    result["name_genitive"] = ""
                    continue

                self.humanizer.human_like_scroll(self.browser)
                soup = BS(self.browser.page_source, "lxml")
                publications = soup.find_all("a", {"class": "list-element__title"})

                if not publications:
                    self.log(f"     ‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
                    # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                    result["found"] = False
                    result["name"] = ""
                    result["address"] = ""
                    result["postal_code"] = ""
                    result["inn"] = ""
                    result["ogrn"] = ""
                    result["name_genitive"] = ""
                    continue

                self.log(f"     ‚úì –ù–∞–π–¥–µ–Ω–æ: {len(publications)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç(–æ–≤)")

                # –û—Ç–∫—Ä—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                link = publications[0]["href"]
                try:
                    link_element = self.humanizer.human_like_wait_for_element(
                        self.browser, (By.XPATH, f"//a[@href='{link}']"), 5
                    )
                    if link_element:
                        self.humanizer.human_like_click(self.browser, link_element)
                    else:
                        self.browser.get(main_url + link)
                except TimeoutException:
                    self.browser.get(main_url + link)

                self.humanizer.human_like_wait(rd.uniform(1.0, 2.0))
                self.humanizer.human_like_scroll(self.browser)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
                if self._extract_organization_data(result):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –Ω–∞–π–¥–µ–Ω–Ω–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ)
                    if self._validate_organization_result(original_org_name, result):
                        self.log(f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ –Ω–∞–π–¥–µ–Ω–æ (–≤–∞—Ä–∏–∞–Ω—Ç {attempt})")
                        return result
                    else:
                        self.log(f"     ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–Ω–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞ –ø—Ä–æ–≤–µ—Ä–∫—É –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏, –ø—Ä–æ–¥–æ–ª–∂–∞—é –ø–æ–∏—Å–∫...")
                        # –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–∏
                        result["found"] = False
                        result["name"] = ""
                        result["address"] = ""
                        result["postal_code"] = ""
                        result["inn"] = ""
                        result["ogrn"] = ""
                        result["name_genitive"] = ""
                        continue
                else:
                    self.log(f"     ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ")
                    # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ —Ç–∞–º –æ—Å—Ç–∞–ª–∏—Å—å –¥–∞–Ω–Ω—ã–µ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π –ø–æ–ø—ã—Ç–∫–∏
                    result["found"] = False
                    result["name"] = ""
                    result["address"] = ""
                    result["postal_code"] = ""
                    result["inn"] = ""
                    result["ogrn"] = ""
                    result["name_genitive"] = ""
                    continue

            except Exception as e:
                self.log(f"     ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ {attempt}: {str(e)}")
                # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–∫–∏
                result["found"] = False
                result["name"] = ""
                result["address"] = ""
                result["postal_code"] = ""
                result["inn"] = ""
                result["ogrn"] = ""
                result["name_genitive"] = ""
                continue

        self.log(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –ø–æ –æ–¥–Ω–æ–º—É –≤–∞—Ä–∏–∞–Ω—Ç—É")
        return result

    def _search_by_inn(self, main_url, inn, result):
        """–ü–æ–∏—Å–∫ –ø–æ –ò–ù–ù (–∏—Å—Ö–æ–¥–Ω–∞—è –ª–æ–≥–∏–∫–∞)"""
        self.browser.get(f"{main_url}/search?query={inn}")
        self.humanizer.human_like_wait(rd.uniform(1.5, 2.5))

        self._handle_rusprofile_captcha()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–∫—Ä—ã–ª–∞—Å—å –ª–∏ —Å—Ä–∞–∑—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
        try:
            name_elem = self.humanizer.human_like_wait_for_element(
                self.browser, (By.ID, "clip_name-long"), 3
            )
            if name_elem:
                self.log("  ‚úì –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞ —Å—Ä–∞–∑—É –ø–æ –ò–ù–ù")
                self.humanizer.human_like_scroll(self.browser)
                if self._extract_organization_data(result):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å (–¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –ò–ù–ù –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤)
                    if self._validate_organization_result("", result, check_keyword_match=False):
                        return result
        except TimeoutException:
            pass

        # –ï—Å–ª–∏ –Ω–µ –æ—Ç–∫—Ä—ã–ª–∞—Å—å —Å—Ä–∞–∑—É, –∏—â–µ–º –≤ —Å–ø–∏—Å–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        try:
            search_result = self.humanizer.human_like_wait_for_element(
                self.browser, (By.CLASS_NAME, "list-element__title"), 5
            )
            if search_result:
                self.humanizer.human_like_scroll(self.browser)
                soup = BS(self.browser.page_source, "lxml")
                publications = soup.find_all("a", {"class": "list-element__title"})

                if publications:
                    self.log(f"  ‚úì –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(publications)}")
                    link = publications[0]["href"]
                    self.browser.get(main_url + link)
                    self.humanizer.human_like_wait(rd.uniform(1.0, 2.0))
                    self._handle_rusprofile_captcha()
                    self.humanizer.human_like_scroll(self.browser)

                    if self._extract_organization_data(result):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å (–¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –ò–ù–ù –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–µ–Ω–µ–µ —Å—Ç—Ä–æ–≥–∞—è)
                        if self._validate_organization_result("", result):
                            return result
        except TimeoutException:
            pass

        self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return result

    def _extract_organization_data(self, result):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            name_elem = self.humanizer.human_like_wait_for_element(
                self.browser, (By.ID, "clip_name-long"), 10
            )
            address_elem = self.humanizer.human_like_wait_for_element(
                self.browser, (By.ID, "clip_address"), 10
            )

            if not name_elem or not address_elem:
                return False

            result["name"] = name_elem.text.strip()
            result["name"] = self.normalize_organization_name(result["name"])
            result["name_genitive"] = self.get_genitive_case_pymorphy(result["name"])
            result["address"] = address_elem.text.strip()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—á—Ç–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
            postal_match = re.search(r"\b(\d{6})\b", result["address"])
            if postal_match:
                result["postal_code"] = postal_match.group(1)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ò–ù–ù –∏ –û–ì–†–ù
            page_text = self.browser.find_element(By.TAG_NAME, "body").text
            inn_match = re.search(r"–ò–ù–ù[:\s]*(\d{10,12})", page_text)
            ogrn_match = re.search(r"–û–ì–†–ù[:\s]*(\d{13,15})", page_text)

            if inn_match:
                result["inn"] = inn_match.group(1)
            if ogrn_match:
                result["ogrn"] = ogrn_match.group(1)

            result["found"] = True
            self.log(f"  ‚úÖ –ò–ù–ù: {result.get('inn')}  –û–ì–†–ù: {result.get('ogrn')}")
            self.log(f"  üìù {result['name'][:70]}...")
            self.log(f"  üìç {result['address'][:70]}...")

            return True

        except TimeoutException:
            return False
        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            return False


class KonturFokusSearcher(BaseSearcher):
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –≤ –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å"""

    def search(self, org_name=None, inn=None):
        """–ü–æ–∏—Å–∫ –≤ –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏–ª–∏ –ò–ù–ù"""
        result = {
            "found": False,
            "name": "",
            "address": "",
            "inn": "",
            "ogrn": "",
            "postal_code": "",
            "name_genitive": "",
        }

        try:
            query = inn if inn else org_name
            if not query:
                return result

            # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            if not inn:
                query = self.remove_quotes_for_search(query)

            url = f"https://focus.kontur.ru/search?country=RU&query={query}"
            self.browser.get(url)
            self.humanizer.human_like_wait(rd.uniform(0.5, 1.0))

            try:
                self.humanizer.human_like_wait_for_element(
                    self.browser, (By.XPATH, "//*[contains(text(), '–ò–ù–ù')]"), 5
                )
                self.humanizer.human_like_wait(rd.uniform(1, 2))
                self.humanizer.human_like_scroll(self.browser)

                page_text = self.browser.find_element(By.TAG_NAME, "body").text

                if "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ" in page_text:
                    self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    return result

                inn_match = re.search(r"–ò–ù–ù[:\s]*(\d{10,12})", page_text)
                if inn_match:
                    result["inn"] = inn_match.group(1)

                ogrn_match = re.search(r"–û–ì–†–ù[:\s]*(\d{13,15})", page_text)
                if ogrn_match:
                    result["ogrn"] = ogrn_match.group(1)

                # –ü–æ–∏—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
                lines = page_text.split("\n")
                for line in lines:
                    if any(
                        word in line.upper()
                        for word in [
                            "–ê–í–¢–û–ù–û–ú–ù–ê–Ø",
                            "–ì–û–°–£–î–ê–†–°–¢–í–ï–ù–ù–ê–Ø",
                            "–ú–£–ù–ò–¶–ò–ü–ê–õ–¨–ù–ê–Ø",
                            "–û–ë–©–ï–û–ë–†–ê–ó–û–í–ê–¢–ï–õ–¨–ù–ê–Ø",
                            "–ù–ï–ö–û–ú–ú–ï–†–ß–ï–°–ö–ê–Ø",
                            "–ë–Æ–î–ñ–ï–¢–ù–ê–Ø",
                            "–ê–í–¢–û–ù–û–ú–ù–û–ï",
                            "–ì–û–°–£–î–ê–†–°–¢–í–ï–ù–ù–û–ï",
                            "–ú–£–ù–ò–¶–ò–ü–ê–õ–¨–ù–û–ï",
                            "–û–ë–©–ï–û–ë–†–ê–ó–û–í–ê–¢–ï–õ–¨–ù–û–ï",
                            "–ù–ï–ö–û–ú–ú–ï–†–ß–ï–°–ö–û–ï",
                            "–ë–Æ–î–ñ–ï–¢–ù–û–ï",
                        ]
                    ):
                        if len(line) > 10 and "–ò–ù–ù" not in line:
                            result["name"] = line.strip()
                            result["name_genitive"] = self.get_genitive_case_pymorphy(
                                result["name"]
                            )
                            break

                # –ü–æ–∏—Å–∫ –∞–¥—Ä–µ—Å–∞
                address_match = re.search(
                    r"(\d{6})[,\s]+([^\n]+(?:–æ–±–ª|–∫—Ä–∞–π|—Ä–µ—Å–ø|–≥\.|–≥ |–æ–±–ª–∞—Å—Ç—å|—Å–µ–≤–∞—Å—Ç–æ–ø–æ–ª—å)[^\n]+)",
                    page_text,
                    re.IGNORECASE,
                )
                if address_match:
                    result["address"] = (
                        address_match.group(1) + ", " + address_match.group(2).strip()
                    )
                    result["postal_code"] = address_match.group(1)

                if result["inn"] or result["name"]:
                    result["found"] = True
                    self.log(f"  ‚úÖ –ò–ù–ù: {result['inn']}, –û–ì–†–ù: {result['ogrn']}")

                    if result["name"]:
                        self.log(f"  üìù {result['name'][:70]}...")
                    else:
                        self.log("  ‚ö†Ô∏è –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

                    if result["address"]:
                        self.log(f"  üìç {result['address'][:70]}...")

            except TimeoutException:
                self.log("  ‚è±Ô∏è Timeout")

        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}")

        return result


class EgrulSearcher(BaseSearcher):
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –≤ –ï–ì–†–Æ–õ"""

    def _load_standardization_rules(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∞–≤–∏–ª —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏"""
        if hasattr(self, "_std_rules"):
            return self._std_rules

        try:
            rules_path = os.path.join(
                os.path.dirname(__file__), "..", "..", "standardization_rules.json"
            )
            with open(rules_path, "r", encoding="utf-8") as f:
                self._std_rules = json.load(f)
                return self._std_rules
        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å standardization_rules.json: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∞–≤–∏–ª
            self._std_rules = {"abbreviations": {}, "type_synonyms": {}}
            return self._std_rules

    def _expand_abbreviations(self, text):
        """–†–∞—Å—à–∏—Ä—è–µ—Ç –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã –≤ —Ç–µ–∫—Å—Ç–µ –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
        rules = self._load_standardization_rules()

        expanded_variants = [text.lower()]

        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä–∞–º–∏
        for abbr, full_form in rules.get("abbreviations", {}).items():
            if abbr.lower() in text.lower():
                variant = re.sub(
                    r"\b" + re.escape(abbr) + r"\b",
                    full_form,
                    text,
                    flags=re.IGNORECASE,
                )
                expanded_variants.append(variant.lower())

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã —Ç–∏–ø–æ–≤ —É—á—Ä–µ–∂–¥–µ–Ω–∏–π
        for type_name, synonyms in rules.get("type_synonyms", {}).items():
            if type_name.lower() in text.lower():
                for synonym in synonyms:
                    expanded_variants.append(synonym.lower())

        return expanded_variants

    def _find_best_educational_match(self, results, query):
        """
        –ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ —É—á—Ä–µ–∂–¥–µ–Ω–∏–µ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç standardization_rules.json –¥–ª—è —É–º–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        """

        rules = self._load_standardization_rules()

        # –°–æ–∑–¥–∞–µ–º –Ω–∞–±–æ—Ä –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –ø—Ä–∞–≤–∏–ª
        edu_keywords = set()

        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã
        for abbr in rules.get("abbreviations", {}).keys():
            edu_keywords.add(abbr.lower())

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
        edu_keywords.update(
            [
                "—à–∫–æ–ª–∞",
                "—Å–æ—à",
                "–ª–∏—Ü–µ–π",
                "–≥–∏–º–Ω–∞–∑–∏—è",
                "–∫–æ–ª–ª–µ–¥–∂",
                "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç",
                "–∏–Ω—Å—Ç–∏—Ç—É—Ç",
                "—É—á–∏–ª–∏—â–µ",
                "–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω",
                "—É—á—Ä–µ–∂–¥–µ–Ω–∏–µ",
                "–¥–µ—Ç—Å–∫–∏–π —Å–∞–¥",
            ]
        )

        # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        negative_keywords = [
            "–ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
            "–ª–∏–∫–≤–∏–¥–∞—Ç–æ—Ä",
            "–ª–∏–∫–≤–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –∫–æ–º–∏—Å—Å–∏–∏",
            "–ø—Ä–∏–∑–Ω–∞–Ω–∏—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π",
            "—Ç–µ–∞—Ç—Ä",
            "—Ä–µ–ª–∏–≥–∏–æ–∑–Ω–∞—è",
            "–ø—Ä–∏—Ö–æ–¥",
            "—Ö—Ä–∞–º",
            "—Ü–µ—Ä–∫–æ–≤—å",
            "—Ç–æ–≤–∞—Ä–∏—â–µ—Å—Ç–≤–æ",
            "—Å–Ω—Ç",
            "—Ç—Å–Ω",
        ]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        query_numbers = set(re.findall(r"\b\d+\b", query))

        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–ø—Ä–æ—Å–∞
        query_variants = self._expand_abbreviations(query)

        candidates = []

        for res in results:
            try:
                text = res.text.lower()

                # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–ª–æ–≤–∞
                if any(neg in text for neg in negative_keywords):
                    continue

                # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —ç—Ç–æ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ —É—á—Ä–µ–∂–¥–µ–Ω–∏–µ
                is_educational = any(keyword in text for keyword in edu_keywords)
                if not is_educational:
                    continue

                # 3. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —á–∏—Å–µ–ª
                result_numbers = set(re.findall(r"\b\d+\b", text))

                if query_numbers:
                    if not query_numbers.intersection(result_numbers):
                        continue

                # 4. –ü–æ–¥—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                score = 0

                # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —á–∏—Å–µ–ª (–æ—á–µ–Ω—å –≤–∞–∂–Ω–æ!)
                score += len(query_numbers.intersection(result_numbers)) * 15

                # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤ –∏–∑ –í–°–ï–• –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
                for variant in query_variants:
                    variant_words = set(re.findall(r"\b[–∞-—è—ë]{3,}\b", variant))
                    result_words = set(re.findall(r"\b[–∞-—è—ë]{3,}\b", text))
                    score += len(variant_words.intersection(result_words)) * 3

                # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä
                for abbr in rules.get("abbreviations", {}).keys():
                    if abbr.lower() in query.lower() and abbr.lower() in text:
                        score += 8

                # –ë–æ–Ω—É—Å –∑–∞ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ —É—á—Ä–µ–∂–¥–µ–Ω–∏—è
                for type_name, synonyms in rules.get("type_synonyms", {}).items():
                    if type_name.lower() in query.lower():
                        if type_name.lower() in text or any(
                            syn.lower() in text for syn in synonyms
                        ):
                            score += 10

                # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ (–µ—Å–ª–∏ —Ä–µ–≥–∏–æ–Ω —É–∫–∞–∑–∞–Ω)
                query_region_words = {
                    "–º–æ—Å–∫–≤",
                    "–º–æ—Å–∫–æ–≤—Å–∫",
                    "—Å–ø–±",
                    "–ø–µ—Ç–µ—Ä–±—É—Ä–≥",
                    "–ª–∏–ø–µ—Ü–∫",
                    "–æ–¥–∏–Ω—Ü–æ–≤",
                }
                for region in query_region_words:
                    if region in query.lower() and region not in text:
                        score -= 5

                candidates.append((score, res, text))

            except Exception as e:
                continue

        if not candidates:
            return None

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        candidates.sort(key=lambda x: x[0], reverse=True)

        self.log(f"  üìä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–æ–ø-3:")
        for i, (score, _, text) in enumerate(candidates[:3], 1):
            self.log(f"    {i}. {score} –±–∞–ª–ª–æ–≤ - {text[:60]}...")

        return candidates[0][1]

    def search(self, org_name):
        """–ü–æ–∏—Å–∫ –≤ –ï–ì–†–Æ–õ —Å —É–º–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        result = {
            "found": False,
            "address": "",
            "postal_code": "",
        }

        try:
            url = "https://egrul.nalog.ru/"
            self.browser.get(url)
            self.humanizer.human_like_wait(rd.uniform(0.5, 1.0))

            try:
                search_field = self.humanizer.human_like_wait_for_element(
                    self.browser, (By.ID, "query"), 7
                )
                if not search_field:
                    self.log("  ‚ö†Ô∏è –ü–æ–ª–µ –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                    return result

                # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞
                search_org_name = self.remove_quotes_for_search(org_name)
                self.humanizer.human_like_type(self.browser, search_field, search_org_name)
                self.humanizer.random_mouse_movement(self.browser, search_field)
                search_field.send_keys(Keys.RETURN)

                self.humanizer.human_like_wait_for_element(
                    self.browser, (By.CLASS_NAME, "res-text"), 10
                )
                self.humanizer.human_like_wait(rd.uniform(1.0, 1.5))
                self.humanizer.human_like_scroll(self.browser)

                # –ò—â–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                try:
                    all_results = self.browser.find_elements(
                        By.CSS_SELECTOR, ".res-text"
                    )

                    if not all_results:
                        self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        return result

                    self.log(f"  üîç –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(all_results)}")

                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                    best_match = self._find_best_educational_match(
                        all_results, org_name
                    )

                    if not best_match:
                        self.log("  ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —É—á—Ä–µ–∂–¥–µ–Ω–∏–π")
                        return result

                    # –ö–ª–∏–∫–∞–µ–º –Ω–∞ –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                    result_link = best_match.find_element(By.TAG_NAME, "a")
                    self.log(f"  ‚úì –í—ã–±—Ä–∞–Ω–æ: {result_link.text[:50]}...")

                    self.humanizer.human_like_click(self.browser, result_link)
                    self.humanizer.human_like_wait(rd.uniform(1.5, 2.5))
                    self.humanizer.human_like_scroll(self.browser)

                    detail_text = self.browser.find_element(By.TAG_NAME, "body").text

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    inn_match = re.search(r"–ò–ù–ù[:\s]*(\d{10,12})", detail_text)
                    if inn_match:
                        result["inn"] = inn_match.group(1)

                    ogrn_match = re.search(r"–û–ì–†–ù[:\s]*(\d{13,15})", detail_text)
                    if ogrn_match:
                        result["ogrn"] = ogrn_match.group(1)

                    name_match = re.search(
                        r"–ü–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ[:\s]*([^\n]+)", detail_text
                    )
                    if name_match:
                        result["name"] = name_match.group(1).strip()
                        result["name_genitive"] = self.get_genitive_case_pymorphy(
                            result["name"]
                        )

                    address_match = re.search(r"–ê–¥—Ä–µ—Å[:\s]*([^\n]+)", detail_text)
                    if address_match:
                        result["address"] = address_match.group(1).strip()
                        postal_match = re.search(r"\b(\d{6})\b", result["address"])
                        if postal_match:
                            result["postal_code"] = postal_match.group(1)

                    # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    if result.get("name") and result.get("address"):
                        result["found"] = True
                        self.log(
                            f"  ‚úÖ –ò–ù–ù: {result.get('inn')}, –û–ì–†–ù: {result.get('ogrn')}"
                        )
                        self.log(f"  üìù {result['name'][:70]}...")
                        self.log(f"  üìç {result['address'][:70]}...")
                    elif result.get("inn") or result.get("ogrn"):
                        result["found"] = False
                        self.log(
                            f"  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω —Ç–æ–ª—å–∫–æ –ò–ù–ù: {result.get('inn')} (–±–µ–∑ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)"
                        )

                except Exception as e:
                    self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {e}")
                    return result

            except TimeoutException:
                self.log("  ‚è±Ô∏è Timeout")

        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}")

        return result


class OrganizationParser:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è—Ö"""

    def __init__(
        self,
        log_callback=None,
        use_gigachat=False,
        gigachat_api=None,
        gigachat_retries=3,
        use_recaptcha_solver=False,
        recaptcha_api_key=None,
        humanization_mode="normal",
    ):
        self.log_callback = log_callback
        self.browser = None
        self.humanizer = Humanization(mode=humanization_mode)
        self.use_gigachat = use_gigachat
        self.gigachat_api = gigachat_api
        self.gigachat_retries = gigachat_retries

        self.use_recaptcha_solver = use_recaptcha_solver
        self.recaptcha_solver = None
        if use_recaptcha_solver and recaptcha_api_key:
            try:
                self.recaptcha_solver = ReCaptchaSolver(
                    api_key=recaptcha_api_key, log_callback=self.log
                )
                self.log("‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∫–∞–ø—á–∏ –≤–∫–ª—é—á–µ–Ω–æ")
            except Exception as e:
                self.log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—à–∞—Ç–µ–ª—å –∫–∞–ø—á–∏: {e}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ–∞—Ä—á–µ—Ä—ã (–ø–æ—Å–ª–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞)
        self.rusprofile_searcher = None
        self.kontur_fokus_searcher = None
        self.egrul_searcher = None

    def log(self, message):
        """–í—ã–≤–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ª–æ–≥"""
        if self.log_callback:
            self.log_callback(message)
        else:
            print(message)

    def init_browser(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ Chrome"""
        chrome_options = wd.ChromeOptions()
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--start-maximized")
        chrome_options.add_argument("--incognito")
        if not config.AppSettings.is_dev_mode:
            chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--log-level=3")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-features=VizDisplayCompositor")
        chrome_options.add_argument(f"--user-data-dir={tempfile.mkdtemp()}")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option("useAutomationExtension", False)
        with open("user_agents.json", "r", encoding="utf-8") as f:
            user_agents = json.load(f)
        selected_user_agent = rd.choice(user_agents)
        chrome_options.add_argument(f"--user-agent={selected_user_agent}")

        self.log("\nüåê –≠–¢–ê–ü 2: –ü–æ–∏—Å–∫ –≤ –±–∞–∑–∞—Ö –¥–∞–Ω–Ω—ã—Ö")
        self.log("=" * 60)
        self.log("üöÄ –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞...")
        self.browser = wd.Chrome(options=chrome_options)
        self.browser.execute_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        )
        self.humanizer.human_like_wait(rd.uniform(0.5, 1.5))

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ–∞—Ä—á–µ—Ä—ã –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –±—Ä–∞—É–∑–µ—Ä–∞
        self.rusprofile_searcher = RusProfileSearcher(
            browser=self.browser,
            humanizer=self.humanizer,
            log_callback=self.log_callback,
            use_recaptcha_solver=self.use_recaptcha_solver,
            recaptcha_solver=self.recaptcha_solver,
        )
        self.kontur_fokus_searcher = KonturFokusSearcher(
            browser=self.browser,
            humanizer=self.humanizer,
            log_callback=self.log_callback,
        )
        self.egrul_searcher = EgrulSearcher(
            browser=self.browser,
            humanizer=self.humanizer,
            log_callback=self.log_callback,
        )

    def close_browser(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞"""
        if self.browser:
            self.browser.quit()
            self.log("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")

    def search_organization(self, org_name):
        """–ö–∞—Å–∫–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏"""
        result = {
            "name": "",
            "address": "",
            "postal_code": "",
            "inn": "",
            "ogrn": "",
            "source": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ",
        }

        # 1. RusProfile
        self.log("üîç –ü–æ–∏—Å–∫ –≤ RusProfile...")
        rusprofile_result = self.rusprofile_searcher.search(org_name=org_name)
        if rusprofile_result["found"]:
            result.update(rusprofile_result)
            result["source"] = "RusProfile"
            return result

        # 2. –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å
        self.log("üîç –ü–æ–∏—Å–∫ –≤ –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å...")
        fokus_result = self.kontur_fokus_searcher.search(org_name=org_name)
        if fokus_result["found"]:
            result.update(fokus_result)
            result["source"] = "–ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å"
            return result

        # 3. –ï–ì–†–Æ–õ - –∏—â–µ–º –ò–ù–ù –∏ –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.log("üîç –ü–æ–∏—Å–∫ –≤ –ï–ì–†–Æ–õ...")
        egrul_result = self.egrul_searcher.search(org_name)
        if egrul_result["found"]:
            result.update(egrul_result)
            result["source"] = "–ï–ì–†–Æ–õ"
            return result

        # –ï—Å–ª–∏ –≤ –ï–ì–†–Æ–õ –Ω–∞—à–ª–∏ –ò–ù–ù (–Ω–æ –Ω–µ –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ), –ø—Ä–æ–±—É–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–∏—Å–∫ –ø–æ –ò–ù–ù
        if egrul_result.get("inn"):
            self.log(
                f"  üîó –ù–∞–π–¥–µ–Ω –ò–ù–ù –≤ –ï–ì–†–Æ–õ: {egrul_result.get('inn')}, –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫..."
            )

            # –ü—Ä–æ–±—É–µ–º RusProfile –ø–æ –ò–ù–ù
            self.log("  üîç –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ RusProfile –ø–æ –ò–ù–ù...")
            rusprofile_result = self.rusprofile_searcher.search(inn=egrul_result.get("inn"))
            if rusprofile_result["found"]:
                result.update(rusprofile_result)
                result["source"] = "–ï–ì–†–Æ–õ ‚Üí RusProfile"
                return result

            # –ü—Ä–æ–±—É–µ–º –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å –ø–æ –ò–ù–ù
            self.log("  üîç –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å –ø–æ –ò–ù–ù...")
            fokus_result = self.kontur_fokus_searcher.search(
                org_name=None, inn=egrul_result.get("inn")
            )
            if fokus_result["found"]:
                result.update(fokus_result)
                result["source"] = "–ï–ì–†–Æ–õ ‚Üí –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å"
                return result

        # 4. GigaChat - –ø—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –≤ –ï–ì–†–Æ–õ —á–µ—Ä–µ–∑ AI (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        if self.gigachat_api:
            self.log("ü§ñ –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ GigaChat (–ø—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –≤ –ï–ì–†–Æ–õ)...")
            gigachat_result = self.search_with_gigachat(org_name)
            if gigachat_result["found"]:
                result.update(gigachat_result)
                result["source"] = "GigaChat (–ï–ì–†–Æ–õ)"
                return result

        self.log("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏–≥–¥–µ")
        return result

    # –ú–µ—Ç–æ–¥—ã get_genitive_case_pymorphy –∏ normalize_organization_name —Ç–µ–ø–µ—Ä—å –≤ BaseSearcher
    # –û—Å—Ç–∞–≤–ª—è–µ–º –∏—Ö –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    @staticmethod
    def get_genitive_case_pymorphy(org_name):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞–¥–µ–∂–∞ —á–µ—Ä–µ–∑ pymorphy3 (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ BaseSearcher)"""
        return BaseSearcher.get_genitive_case_pymorphy(org_name)

    @staticmethod
    def normalize_organization_name(name):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ BaseSearcher)"""
        return BaseSearcher.normalize_organization_name(name)

    # –°—Ç–∞—Ä—ã–µ –º–µ—Ç–æ–¥—ã –ø–æ–∏—Å–∫–∞ –æ—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–æ –¥–µ–ª–µ–≥–∏—Ä—É—é—Ç –≤ —Å–µ–∞—Ä—á–µ—Ä—ã
    def search_rusprofile(self, org_name=None, inn=None):
        """–ü–æ–∏—Å–∫ –≤ RusProfile (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ RusProfileSearcher)"""
        if not self.rusprofile_searcher:
            # –ï—Å–ª–∏ –±—Ä–∞—É–∑–µ—Ä –µ—â–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return {"found": False}
        return self.rusprofile_searcher.search(org_name=org_name, inn=inn)

    def search_kontur_fokus(self, org_name=None, inn=None):
        """–ü–æ–∏—Å–∫ –≤ –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ KonturFokusSearcher)"""
        if not self.kontur_fokus_searcher:
            return {"found": False}
        return self.kontur_fokus_searcher.search(org_name=org_name, inn=inn)

    def search_egrul(self, org_name):
        """–ü–æ–∏—Å–∫ –≤ –ï–ì–†–Æ–õ (–¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ EgrulSearcher)"""
        if not self.egrul_searcher:
            return {"found": False}
        return self.egrul_searcher.search(org_name)

    # –£–¥–∞–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã (—Ç–µ–ø–µ—Ä—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Å–µ–∞—Ä—á–µ—Ä–∞—Ö):
    # - _handle_rusprofile_captcha -> RusProfileSearcher
    # - generate_search_variants -> RusProfileSearcher
    # - _search_by_name_with_variants -> RusProfileSearcher
    # - _search_by_inn -> RusProfileSearcher
    # - _extract_organization_data -> RusProfileSearcher
    # - _load_standardization_rules -> EgrulSearcher
    # - _expand_abbreviations -> EgrulSearcher
    # - _find_best_educational_match -> EgrulSearcher

    def search_with_gigachat(self, org_name):
        """–ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –≤ –ï–ì–†–Æ–õ —á–µ—Ä–µ–∑ GigaChat"""
        result = {
            "found": False,
            "address": "",
            "postal_code": "",
        }

        try:
            gigachat_result = self.gigachat_api.search_organization_in_egrul(org_name)

            if gigachat_result["found"]:
                result.update(gigachat_result)
                return result
            else:
                self.log("  ‚ö†Ô∏è GigaChat –Ω–µ –Ω–∞—à–µ–ª –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é")

        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ GigaChat: {str(e)}")

        return result
