"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
"""

import re
import json
import random as rd
import tempfile
import pymorphy3
from selenium import webdriver as wd
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup as BS

import config
from .humanization import Humanization


class OrganizationParser:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è—Ö"""

    def __init__(
        self,
        log_callback=None,
        use_gigachat=False,
        gigachat_api=None,
        gigachat_retries=3,
    ):
        self.log_callback = log_callback
        self.browser = None
        self.humanizer = Humanization()
        self.use_gigachat = use_gigachat
        self.gigachat_api = gigachat_api
        self.gigachat_retries = gigachat_retries

    def log(self, message):
        """–í—ã–≤–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ª–æ–≥"""
        if self.log_callback:
            self.log_callback(message)
        else:
            print(message)

    def init_browser(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞ Chrome"""
        chrome_options = wd.ChromeOptions()
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--start-maximized")
        chrome_options.add_argument("--incognito")
        if not config.AppSettings.is_dev_mode:
            chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--log-level=3")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-features=VizDisplayCompositor")
        chrome_options.add_argument(f"--user-data-dir={tempfile.mkdtemp()}")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option("useAutomationExtension", False)
        with open("user_agents.json", "r", encoding="utf-8") as f:
            user_agents = json.load(f)
        selected_user_agent = rd.choice(user_agents)
        chrome_options.add_argument(f'--user-agent={selected_user_agent}')

        self.log("\nüåê –≠–¢–ê–ü 2: –ü–æ–∏—Å–∫ –≤ –±–∞–∑–∞—Ö –¥–∞–Ω–Ω—ã—Ö")
        self.log("=" * 60)
        self.log("üöÄ –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞...")
        self.browser = wd.Chrome(options=chrome_options)
        self.browser.execute_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        )
        self.humanizer.human_like_wait(rd.uniform(0.5, 1.5))

    def close_browser(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞"""
        if self.browser:
            self.browser.quit()
            self.log("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")

    def search_organization(self, org_name):
        """–ö–∞—Å–∫–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏"""
        result = {
            "name": "",
            "address": "",
            "postal_code": "",
            "inn": "",
            "ogrn": "",
            "source": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ",
        }

        # 1. RusProfile
        self.log("üîç –ü–æ–∏—Å–∫ –≤ RusProfile...")
        rusprofile_result = self.search_rusprofile(org_name)
        if rusprofile_result["found"]:
            result.update(rusprofile_result)
            result["source"] = "RusProfile"
            return result

        # 2. –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å
        self.log("üîç –ü–æ–∏—Å–∫ –≤ –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å...")
        fokus_result = self.search_kontur_fokus(org_name)
        if fokus_result["found"]:
            result.update(fokus_result)
            result["source"] = "–ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å"
            return result

        # 3. –ï–ì–†–Æ–õ - –∏—â–µ–º –ò–ù–ù –∏ –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.log("üîç –ü–æ–∏—Å–∫ –≤ –ï–ì–†–Æ–õ...")
        egrul_result = self.search_egrul(org_name)
        if egrul_result["found"]:
            result.update(egrul_result)
            result["source"] = "–ï–ì–†–Æ–õ"
            return result

        # –ï—Å–ª–∏ –≤ –ï–ì–†–Æ–õ –Ω–∞—à–ª–∏ –ò–ù–ù (–Ω–æ –Ω–µ –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ), –ø—Ä–æ–±—É–µ–º –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–∏—Å–∫ –ø–æ –ò–ù–ù
        if egrul_result.get("inn"):
            self.log(
                f"  üîó –ù–∞–π–¥–µ–Ω –ò–ù–ù –≤ –ï–ì–†–Æ–õ: {egrul_result.get('inn')}, –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫..."
            )

            # –ü—Ä–æ–±—É–µ–º RusProfile –ø–æ –ò–ù–ù
            self.log("  üîç –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ RusProfile –ø–æ –ò–ù–ù...")
            rusprofile_result = self.search_rusprofile(inn=egrul_result.get("inn"))
            if rusprofile_result["found"]:
                result.update(rusprofile_result)
                result["source"] = "–ï–ì–†–Æ–õ ‚Üí RusProfile"
                return result

            # –ü—Ä–æ–±—É–µ–º –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å –ø–æ –ò–ù–ù
            self.log("  üîç –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å –ø–æ –ò–ù–ù...")
            fokus_result = self.search_kontur_fokus(
                org_name=None, inn=egrul_result.get("inn")
            )
            if fokus_result["found"]:
                result.update(fokus_result)
                result["source"] = "–ï–ì–†–Æ–õ ‚Üí –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å"
                return result

        # 4. GigaChat - –ø—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –≤ –ï–ì–†–Æ–õ —á–µ—Ä–µ–∑ AI (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω)
        if self.gigachat_api:
            self.log("ü§ñ –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ GigaChat (–ø—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –≤ –ï–ì–†–Æ–õ)...")
            gigachat_result = self.search_with_gigachat(org_name)
            if gigachat_result["found"]:
                result.update(gigachat_result)
                result["source"] = "GigaChat (–ï–ì–†–Æ–õ)"
                return result

        self.log("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏–≥–¥–µ")
        return result

    @staticmethod
    def get_genitive_case_pymorphy(org_name):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞–¥–µ–∂–∞ —á–µ—Ä–µ–∑ pymorphy3"""
        if not org_name:
            return org_name
        
        morph = pymorphy3.MorphAnalyzer()  # ‚Üê –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ pymorphy3
        
        # –û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        words = org_name.split()
        genitive_words = []
        
        for word in words:
            if word.startswith(('¬´', '"', '"')) or word.endswith(('¬ª', '"', '"')):
                genitive_words.append(word)
            else:
                clean_word = word.strip('.,;:!?')
                punct = word[len(clean_word):] if len(word) > len(clean_word) else ''
                
                parsed = morph.parse(clean_word)[0]
                genitive_form = parsed.inflect({'gent'})
                
                if genitive_form:
                    genitive_words.append(genitive_form.word.capitalize() if clean_word[0].isupper() else genitive_form.word + punct)
                else:
                    genitive_words.append(word)
        
        return ' '.join(genitive_words)

    @staticmethod
    def normalize_organization_name(name):
        """
        –ü—Ä–∏–≤–æ–¥–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É:
        - –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã
        - –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ —Å–æ —Å—Ç—Ä–æ—á–Ω–æ–π
        - –¢–µ–∫—Å—Ç –≤ –∫–∞–≤—ã—á–∫–∞—Ö —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –ø–µ—Ä–≤–æ–π –±—É–∫–≤—ã
        """
        if not name:
            return name
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö (–ª—é–±—ã–µ —Ç–∏–ø—ã –∫–∞–≤—ã—á–µ–∫)
        quote_pattern = r'[¬´"\'"][^¬´¬ª"\'""]+[¬ª"\'""]'
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –∫–∞–≤—ã—á–∫–∞–º–∏ –∏ –∏—Ö –ø–æ–∑–∏—Ü–∏–∏
        matches = list(re.finditer(quote_pattern, name))
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–∞–≤—ã—á–µ–∫, –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É
        if not matches:
            return name.capitalize()
        
        result = []
        last_end = 0
        
        for i, match in enumerate(matches):
            start, end = match.span()
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –î–û –∫–∞–≤—ã—á–µ–∫
            before_text = name[last_end:start]
            if before_text:
                words = before_text.split()
                normalized_words = []
                for j, word in enumerate(words):
                    # –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –≤—Å–µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è - —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π
                    if last_end == 0 and j == 0:
                        normalized_words.append(word.capitalize())
                    else:
                        normalized_words.append(word.lower())
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–±–µ–ª –≤ –∫–æ–Ω—Ü–µ –µ—Å–ª–∏ –æ–Ω –±—ã–ª
                normalized_before = ' '.join(normalized_words)
                if before_text.endswith(' '):
                    normalized_before += ' '
                result.append(normalized_before)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –í –∫–∞–≤—ã—á–∫–∞—Ö
            quoted_text = match.group()
            opening_quote = quoted_text[0]
            closing_quote = quoted_text[-1]
            inner_text = quoted_text[1:-1]
            
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É: –ø–µ—Ä–≤–∞—è –±—É–∫–≤–∞ –∑–∞–≥–ª–∞–≤–Ω–∞—è, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ—á–Ω—ã–µ
            normalized_inner = inner_text.capitalize()
            result.append(f'{opening_quote}{normalized_inner}{closing_quote}')
            
            last_end = end
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞—Ç–æ–∫ —Ç–µ–∫—Å—Ç–∞ –ü–û–°–õ–ï –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∫–∞–≤—ã—á–µ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if last_end < len(name):
            after_text = name[last_end:]
            words = after_text.split()
            normalized_words = [word.lower() for word in words]
            result.append(' '.join(normalized_words))
        
        return ''.join(result)

    def search_rusprofile(self, org_name=None, inn=None):
        """–ü–æ–∏—Å–∫ –≤ RusProfile –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏–ª–∏ –ò–ù–ù"""
        result = {"found": False}

        try:
            main_url = "https://www.rusprofile.ru"

            if inn:
                # –ü–æ–∏—Å–∫ –ø–æ –ò–ù–ù
                self.browser.get(f"{main_url}/search?query={inn}")
                self.humanizer.human_like_wait(rd.uniform(1.5, 2.5))

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–∫—Ä—ã–ª–∞—Å—å –ª–∏ —Å—Ä–∞–∑—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
                try:
                    name_elem = self.humanizer.human_like_wait_for_element(
                        self.browser, (By.ID, "clip_name-long"), 3
                    )
                    if name_elem:
                        self.log("  ‚úì –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞ —Å—Ä–∞–∑—É –ø–æ –ò–ù–ù")
                        self.humanizer.human_like_scroll(self.browser)
                    else:
                        # –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        try:
                            search_result = self.humanizer.human_like_wait_for_element(
                                self.browser, (By.CLASS_NAME, "list-element__title"), 5
                            )
                            if search_result:
                                self.humanizer.human_like_scroll(self.browser)
                                soup = BS(self.browser.page_source, "lxml")
                                publications = soup.find_all(
                                    "a", {"class": "list-element__title"}
                                )

                                if publications:
                                    self.log(
                                        f"  ‚úì –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(publications)}"
                                    )
                                    link = publications[0]["href"]
                                    self.browser.get(main_url + link)
                                    self.humanizer.human_like_wait(rd.uniform(1.0, 2.0))
                                    self.humanizer.human_like_scroll(self.browser)
                                else:
                                    self.log("  ‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
                                    return result
                            else:
                                self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                                return result
                        except TimeoutException:
                            self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                            return result
                except TimeoutException:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    try:
                        search_result = self.humanizer.human_like_wait_for_element(
                            self.browser, (By.CLASS_NAME, "list-element__title"), 5
                        )
                        if search_result:
                            self.humanizer.human_like_scroll(self.browser)
                            soup = BS(self.browser.page_source, "lxml")
                            publications = soup.find_all(
                                "a", {"class": "list-element__title"}
                            )

                            if publications:
                                self.log(
                                    f"  ‚úì –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(publications)}"
                                )
                                link = publications[0]["href"]
                                self.browser.get(main_url + link)
                                self.humanizer.human_like_wait(rd.uniform(1.0, 2.0))
                                self.humanizer.human_like_scroll(self.browser)
                            else:
                                self.log("  ‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
                                return result
                        else:
                            self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                            return result
                    except TimeoutException:
                        self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        return result
            else:
                # –ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
                self.browser.get(main_url + "/search-advanced")
                self.humanizer.human_like_wait(rd.uniform(0.5, 1.0))

                try:
                    search = self.humanizer.human_like_wait_for_element(
                        self.browser, (By.ID, "advanced-search-query"), 10
                    )
                    if not search:
                        self.log("  ‚ö†Ô∏è –ù–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è –ø–æ–∏—Å–∫")
                        return result

                    self.humanizer.human_like_type(self.browser, search, org_name)
                    self.humanizer.random_mouse_movement(self.browser, search)
                    search.send_keys(Keys.ENTER)
                    self.humanizer.human_like_wait(rd.uniform(1.0, 2.0))
                except TimeoutException:
                    self.log("  ‚ö†Ô∏è –ù–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è –ø–æ–∏—Å–∫")
                    return result

                try:
                    search_result = self.humanizer.human_like_wait_for_element(
                        self.browser, (By.CLASS_NAME, "list-element__title"), 10
                    )
                    if not search_result:
                        self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        return result
                    self.humanizer.human_like_wait(rd.uniform(0.5, 1.0))
                except TimeoutException:
                    self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    return result

                self.humanizer.human_like_scroll(self.browser)
                soup = BS(self.browser.page_source, "lxml")
                publications = soup.find_all("a", {"class": "list-element__title"})

                if not publications:
                    self.log("  ‚ö†Ô∏è –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
                    return result

                self.log(f"  ‚úì –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(publications)}")

                link = publications[0]["href"]
                try:
                    link_element = self.humanizer.human_like_wait_for_element(
                        self.browser, (By.XPATH, f"//a[@href='{link}']"), 5
                    )
                    if link_element:
                        self.humanizer.human_like_click(self.browser, link_element)
                    else:
                        self.browser.get(main_url + link)
                except TimeoutException:
                    self.browser.get(main_url + link)

                self.humanizer.human_like_wait(rd.uniform(1.0, 2.0))
                self.humanizer.human_like_scroll(self.browser)

            try:
                name_elem = self.humanizer.human_like_wait_for_element(
                    self.browser, (By.ID, "clip_name-long"), 10
                )
                address_elem = self.humanizer.human_like_wait_for_element(
                    self.browser, (By.ID, "clip_address"), 10
                )
                if not name_elem or not address_elem:
                    self.log("  ‚ö†Ô∏è –ù–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å —ç–ª–µ–º–µ–Ω—Ç—ã")
                    return result
            except TimeoutException:
                self.log("  ‚ö†Ô∏è –ù–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å —ç–ª–µ–º–µ–Ω—Ç—ã")
                return result

            result["name"] = name_elem.text.strip()
            result["name"] = self.normalize_organization_name(result["name"])
            result["name_genitive"] = self.get_genitive_case_pymorphy(result["name"])
            result["address"] = address_elem.text.strip()

            postal_match = re.search(r"\b(\d{6})\b", result["address"])
            if postal_match:
                result["postal_code"] = postal_match.group(1)

            page_text = self.browser.find_element(By.TAG_NAME, "body").text
            inn_match = re.search(r"–ò–ù–ù[:\s]*(\d{10,12})", page_text)
            ogrn_match = re.search(r"–û–ì–†–ù[:\s]*(\d{13,15})", page_text)

            if inn_match:
                result["inn"] = inn_match.group(1)
            if ogrn_match:
                result["ogrn"] = ogrn_match.group(1)

            result["found"] = True
            self.log(f"  ‚úÖ –ò–ù–ù: {result.get('inn')}  –û–ì–†–ù: {result.get('ogrn')}")
            self.log(f"  üìù {result['name'][:70]}...")
            self.log(f"  üìç {result['address'][:70]}...")

        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}")

        return result

    def search_kontur_fokus(self, org_name=None, inn=None):
        """–ü–æ–∏—Å–∫ –≤ –ö–æ–Ω—Ç—É—Ä –§–æ–∫—É—Å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏–ª–∏ –ò–ù–ù"""
        result = {"found": False}

        try:
            query = inn if inn else org_name
            if not query:
                return result

            url = f"https://focus.kontur.ru/search?country=RU&query={query}"
            self.browser.get(url)
            self.humanizer.human_like_wait(rd.uniform(0.5, 1.0))

            try:
                self.humanizer.human_like_wait_for_element(
                    self.browser, (By.XPATH, "//*[contains(text(), '–ò–ù–ù')]"), 5
                )
                self.humanizer.human_like_wait(rd.uniform(1, 2))
                self.humanizer.human_like_scroll(self.browser)

                page_text = self.browser.find_element(By.TAG_NAME, "body").text

                if "–ù–∞–π–¥–µ–Ω–æ 0" in page_text or "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ" in page_text:
                    self.log("  ‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    return result

                inn_match = re.search(r"–ò–ù–ù[:\s]*(\d{10,12})", page_text)
                if inn_match:
                    result["inn"] = inn_match.group(1)

                ogrn_match = re.search(r"–û–ì–†–ù[:\s]*(\d{13,15})", page_text)
                if ogrn_match:
                    result["ogrn"] = ogrn_match.group(1)

                lines = page_text.split("\n")
                for line in lines:
                    if any(
                        word in line.upper()
                        for word in [
                            "–ê–í–¢–û–ù–û–ú–ù–ê–Ø",
                            "–ì–û–°–£–î–ê–†–°–¢–í–ï–ù–ù–ê–Ø",
                            "–ú–£–ù–ò–¶–ò–ü–ê–õ–¨–ù–ê–Ø",
                            "–û–ë–©–ï–û–ë–†–ê–ó–û–í–ê–¢–ï–õ–¨–ù–ê–Ø",
                            "–ù–ï–ö–û–ú–ú–ï–†–ß–ï–°–ö–ê–Ø",
                        ]
                    ):
                        if len(line) > 20 and "–ò–ù–ù" not in line:
                            result["name"] = line.strip()
                            result["name_genitive"] = self.get_genitive_case_pymorphy(result["name"])
                            break

                address_match = re.search(
                    r"(\d{6})[,\s]+([^\n]+(?:–æ–±–ª|–∫—Ä–∞–π|—Ä–µ—Å–ø|–≥\.|–≥ |–æ–±–ª–∞—Å—Ç—å)[^\n]+)",
                    page_text,
                )
                if address_match:
                    result["address"] = (
                        address_match.group(1) + ", " + address_match.group(2).strip()
                    )
                    result["postal_code"] = address_match.group(1)

                if result["inn"] or result["name"]:
                    result["found"] = True
                    self.log(f"  ‚úÖ –ò–ù–ù: {result['inn']}, –û–ì–†–ù: {result['ogrn']}")
                    if result["name"]:
                        self.log(f"  üìù {result['name'][:70]}...")
                    if result["address"]:
                        self.log(f"  üìç {result['address'][:70]}...")

            except TimeoutException:
                self.log("  ‚è±Ô∏è Timeout")

        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}")

        return result

    def search_egrul(self, org_name):
        """–ü–æ–∏—Å–∫ –≤ –ï–ì–†–Æ–õ"""
        result = {"found": False}

        try:
            url = "https://egrul.nalog.ru/"
            self.browser.get(url)
            self.humanizer.human_like_wait(rd.uniform(0.5, 1.0))

            try:
                search_field = self.humanizer.human_like_wait_for_element(
                    self.browser, (By.ID, "query"), 7
                )
                if not search_field:
                    self.log("  ‚ö†Ô∏è –ü–æ–ª–µ –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                    return result

                self.humanizer.human_like_type(self.browser, search_field, org_name)
                self.humanizer.random_mouse_movement(self.browser, search_field)
                search_field.send_keys(Keys.RETURN)

                self.humanizer.human_like_wait_for_element(
                    self.browser, (By.CLASS_NAME, "res-text"), 10
                )
                self.humanizer.human_like_wait(rd.uniform(1.0, 1.5))
                self.humanizer.human_like_scroll(self.browser)

                page_text = self.browser.find_element(By.TAG_NAME, "body").text

                inn_match = re.search(r"–ò–ù–ù[:\s]*(\d{10,12})", page_text)
                ogrn_match = re.search(r"–û–ì–†–ù[:\s]*(\d{13,15})", page_text)

                if inn_match:
                    result["inn"] = inn_match.group(1)
                if ogrn_match:
                    result["ogrn"] = ogrn_match.group(1)

                try:
                    first_result = self.humanizer.human_like_wait_for_element(
                        self.browser, (By.CSS_SELECTOR, ".res-text a"), 5
                    )
                    if first_result:
                        self.humanizer.human_like_click(self.browser, first_result)
                        self.humanizer.human_like_wait(rd.uniform(1.5, 2.5))
                        self.humanizer.human_like_scroll(self.browser)
                    detail_text = self.browser.find_element(By.TAG_NAME, "body").text

                    name_match = re.search(
                        r"–ü–æ–ª–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ[:\s]*([^\n]+)", detail_text
                    )
                    if name_match:
                        result["name"] = name_match.group(1).strip()
                        result["name_genitive"] = self.get_genitive_case_pymorphy(result["name"])

                    address_match = re.search(r"–ê–¥—Ä–µ—Å[:\s]*([^\n]+)", detail_text)
                    if address_match:
                        result["address"] = address_match.group(1).strip()
                        postal_match = re.search(r"\b(\d{6})\b", result["address"])
                        if postal_match:
                            result["postal_code"] = postal_match.group(1)
                except Exception:
                    pass

                # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if result.get("name") and result.get("address"):
                    result["found"] = True
                    self.log(
                        f"  ‚úÖ –ò–ù–ù: {result.get('inn')}, –û–ì–†–ù: {result.get('ogrn')}"
                    )
                    self.log(f"  üìù {result['name'][:70]}...")
                    self.log(f"  üìç {result['address'][:70]}...")
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –ò–ù–ù - –Ω–µ –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ found
                elif result.get("inn") or result.get("ogrn"):
                    result["found"] = False
                    self.log(
                        f"  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω —Ç–æ–ª—å–∫–æ –ò–ù–ù: {result.get('inn')} (–±–µ–∑ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)"
                    )

            except TimeoutException:
                self.log("  ‚è±Ô∏è Timeout")

        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)}")

        return result

    def search_with_gigachat(self, org_name):
        """–ü—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –≤ –ï–ì–†–Æ–õ —á–µ—Ä–µ–∑ GigaChat"""
        result = {"found": False}

        try:
            gigachat_result = self.gigachat_api.search_organization_in_egrul(org_name)

            if gigachat_result["found"]:
                result.update(gigachat_result)
                return result
            else:
                self.log("  ‚ö†Ô∏è GigaChat –Ω–µ –Ω–∞—à–µ–ª –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é")

        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ GigaChat: {str(e)}")

        return result
