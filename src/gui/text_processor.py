"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
"""

import re
import threading
from queue import Queue
import language_tool_python


class TextProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π"""

    def __init__(self, log_callback=None):
        self.tool = language_tool_python.LanguageTool("ru")
        self.log_callback = log_callback

    def log(self, message):
        """–í—ã–≤–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ª–æ–≥"""
        if self.log_callback:
            self.log_callback(message)
        else:
            print(message)

    def create_correct_spelling(self, word):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ —Å–ª–æ–≤–∞"""
        result_queue = Queue()

        def check_word():
            try:
                matches = self.tool.check(word)
                if matches:
                    corrected_word = self.tool.correct(word)
                else:
                    corrected_word = word
                result_queue.put(corrected_word)
            except Exception as e:
                result_queue.put((word, f"–û—à–∏–±–∫–∞: {str(e)}"))

        thread = threading.Thread(target=check_word)
        thread.start()
        thread.join(timeout=10.0)

        if thread.is_alive():
            self.log(f"  ‚è±Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è —Å–ª–æ–≤–∞: {word}")
            thread.join()
            return word
        else:
            self.log(f"  ‚úì –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: {word}")

        result_correct_word = result_queue.get()
        if isinstance(result_correct_word, tuple):
            self.log(f"  ‚ö†Ô∏è {result_correct_word[1]}")
            result_correct_word = result_correct_word[0]

        return result_correct_word

    def remove_geo_mentions(self, text):
        """–£–¥–∞–ª–µ–Ω–∏–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        result_correct_text = re.sub(r'(.*)".*$', r'\1"', text)
        return result_correct_text

    def clean_text(self, text):
        """–û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞—Å—Ç–∏ –≤ –∫–∞–≤—ã—á–∫–∞—Ö
        quoted_parts = re.findall(r'"(.*?)"', text)

        temp_text = text
        for part in quoted_parts:
            temp_text = re.sub(rf'"{re.escape(part)}"', "", temp_text)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª–æ–≤–∞ –≤–Ω–µ –∫–∞–≤—ã—á–µ–∫
        words = temp_text.split()
        corrected_words = []

        for word in words:
            if word.isupper():
                corrected_words.append(word)
            else:
                corrected_words.append(word.lower())

        cleaned_text = " ".join(corrected_words).strip()
        if cleaned_text:
            cleaned_text = cleaned_text[0].upper() + cleaned_text[1:]

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –Ω–∞ –º–µ—Å—Ç–æ
        for part in quoted_parts:
            insert_pos = text.find(f'"{part}"')
            if insert_pos != -1:
                cleaned_text = (
                    cleaned_text[:insert_pos] + f'"{part}"' + cleaned_text[insert_pos:]
                )

        intermediate_result = cleaned_text

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
        words = intermediate_result.split()
        corrected_words = []

        self.log(f"  üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ ({len(words)} —Å–ª–æ–≤)...")

        for idx, word in enumerate(words, 1):
            corrected_word = self.create_correct_spelling(word)
            corrected_words.append(corrected_word)

            # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5 —Å–ª–æ–≤
            if idx % 5 == 0:
                self.log(f"  üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–ª–æ–≤: {idx}/{len(words)}")

        cleaned_text = " ".join(corrected_words)
        return cleaned_text

    def convert_names_for_parse(self, raw_data_column):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        result = []
        total = len(raw_data_column)

        self.log(f"\n{'='*60}")
        self.log(f"üîÑ –ù–∞—á–∏–Ω–∞—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é {total} –∑–∞–ø–∏—Å–µ–π...")
        self.log(f"{'='*60}\n")

        for idx, company_name in enumerate(raw_data_column, 1):
            self.log(f"\nüìå [{idx}/{total}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {company_name[:60]}...")

            # –£–¥–∞–ª—è–µ–º –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
            company_name = self.remove_geo_mentions(company_name)
            self.log(f"  ‚úì –£–¥–∞–ª–µ–Ω—ã –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è")

            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
            company_name = self.clean_text(company_name)

            result.append(company_name)
            self.log(f"  ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {company_name[:60]}...")

        self.log(f"\n{'='*60}")
        self.log(f"‚úÖ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total}")
        self.log(f"{'='*60}\n")

        return result

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏"""
        if self.tool:
            self.tool.close()
