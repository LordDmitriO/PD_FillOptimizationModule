"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
"""

import re
import time
import json
import os
from PySide6.QtCore import QThread, Signal
import language_tool_python


class TextProcessor(QThread):
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π"""

    # –°–∏–≥–Ω–∞–ª—ã –¥–ª—è —Å–≤—è–∑–∏ —Å UI
    log_signal = Signal(str)           # –õ–æ–≥–∏
    progress_signal = Signal(int)      # –ü—Ä–æ–≥—Ä–µ—Å—Å (0-100)
    finished_signal = Signal(list)     # –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    # error_signal = Signal(str)         # –û—à–∏–±–∫–∏

    def __init__(self, raw_data_column):
        super().__init__()
        self.raw_data_column = raw_data_column
        # self.convert_time_start = 0
        # self.convert_time_end = None
        # self.convert_time_result = None
        self.tool = None
        self._is_cancelled = False

        self.rules = {
            "abbreviations": {},
            "geo_markers": [],
            "type_synonyms": {}
        }

        self.load_standartization_rules()
        self.compile_regex()

    def load_standartization_rules(self):
        try:
            with open("standardization_rules.json", "r", encoding="utf-8") as f:
                data = json.load(f)
                self.rules["abbreviations"] = data.get("abbreviations", {})
                self.rules["geo_markers"] = data.get("geo_markers", [])
                self.rules["type_synonyms"] = data.get("type_synonyms", {})
        except Exception as e:
            self.log(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ standardization_rules.json: {e}")

    def compile_regex(self):
        """–ö–æ–º–ø–∏–ª—è—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª"""
        geo_list = self.rules["geo_markers"]
        if geo_list:
            geo_list = sorted(geo_list, key=len, reverse=True)
            geo_pattern = r'(?:\b|^)(' + '|'.join(map(re.escape, geo_list)) + r')(?:\b|\s|$)'
            self.geo_regex = re.compile(geo_pattern, re.IGNORECASE)
        else:
            self.geo_regex = re.compile(r'(?!x)x')

        self.replacements = {}

        for short_name, synonyms in self.rules["type_synonyms"].items():
            for syn in synonyms:
                self.replacements[syn.lower()] = short_name

        for abbr, full_name in self.rules["abbreviations"].items():
            if full_name:
                self.replacements[full_name.lower()] = abbr

    def cancel(self):
        """–û—Ç–º–µ–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        self._is_cancelled = True

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥, –≤—ã–ø–æ–ª–Ω—è—é—â–∏–π—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        self.convert_time_start = time.time()
        result = []

        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LanguageTool —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
            self.log("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏...")
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫—ç—à –¥–ª—è LanguageTool, —á—Ç–æ–±—ã –Ω–µ —Å–∫–∞—á–∏–≤–∞—Ç—å –∫–∞–∂–¥—ã–π —Ä–∞–∑
            cache_dir = os.path.expanduser("~/.cache/language_tool_python")
            os.makedirs(cache_dir, exist_ok=True)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—É—Ç—å –∫ –∫—ç—à—É —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
            # –≠—Ç–æ –∑–∞—Å—Ç–∞–≤–∏—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫—ç—à
            if "LANGUAGETOOL_CACHE_DIR" not in os.environ:
                os.environ["LANGUAGETOOL_CACHE_DIR"] = cache_dir
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é —É—Å—Ç–∞–Ω–æ–≤–∫—É LanguageTool (–µ—Å–ª–∏ –µ—Å—Ç—å)
            local_lt_path = "/opt/languagetool"
            if os.path.exists(local_lt_path):
                # –ò—â–µ–º jar —Ñ–∞–π–ª LanguageTool –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–µ
                jar_found = False
                for root, dirs, files in os.walk(local_lt_path):
                    for file in files:
                        if file == "languagetool.jar" or (file.startswith("LanguageTool-") and file.endswith(".jar")):
                            jar_path = os.path.join(root, file)
                            self.log(f"üì¶ –ò—Å–ø–æ–ª—å–∑—É—é –ª–æ–∫–∞–ª—å–Ω—É—é —É—Å—Ç–∞–Ω–æ–≤–∫—É LanguageTool: {jar_path}")
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é —É—Å—Ç–∞–Ω–æ–≤–∫—É —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
                            os.environ["LANGUAGETOOL_JAR"] = jar_path
                            jar_found = True
                            break
                    if jar_found:
                        break
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω—ã–π LanguageTool –≤ –∫—ç—à–µ
            cache_zip = os.path.join(cache_dir, "LanguageTool-latest-snapshot.zip")
            cache_extracted = os.path.join(cache_dir, "LanguageTool-latest-snapshot")
            
            if os.path.exists(cache_zip) or os.path.exists(cache_extracted):
                self.log(f"‚úÖ –ù–∞–π–¥–µ–Ω –∫—ç—à LanguageTool –≤ {cache_dir}")
                self.log("üì¶ –ò—Å–ø–æ–ª—å–∑—É—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é (–±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏)")
            else:
                self.log("üì• LanguageTool –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫—ç—à–µ, –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∑–∞–≥—Ä—É–∑–∫–∞ (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)")
            
            # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è
            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç –ø–æ–≤—Ç–æ—Ä–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—É—Å–∫–µ
            if "LANGUAGETOOL_DISABLE_UPDATE_CHECK" not in os.environ:
                os.environ["LANGUAGETOOL_DISABLE_UPDATE_CHECK"] = "1"
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LanguageTool
            # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            # –ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –∑–∞–≥—Ä—É–∑–∏—Ç LanguageTool, –ø—Ä–∏ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—ç—à
            self.tool = language_tool_python.LanguageTool("ru")

            total = len(self.raw_data_column)

            self.log(f"\n{'='*60}")
            self.log(f"üîÑ –ù–∞—á–∏–Ω–∞—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é {total} –∑–∞–ø–∏—Å–µ–π...")
            self.log(f"{'='*60}\n")

            for idx, company_name in enumerate(self.raw_data_column, 1):
                if self._is_cancelled:
                    self.log("\n‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                    return

                origin_company_name = str(company_name).strip()
                # self.log(f"\nüìå [{idx}/{total}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {company_name[:60]}...")

                company_name_no_geo = self.remove_geo_mentions(origin_company_name)
                company_namee_standardized = self.standardize_names(company_name_no_geo)
                company_nam_cleaned = self.clean_formatting(company_namee_standardized)
                final_company_name = self.check_and_correct(company_nam_cleaned)

                result.append(final_company_name)

                if idx % 5 == 0 or idx == total:
                    self.log(f"[{idx}/{total}] –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {final_company_name[:40]}...")

                progress = int((idx / total) * 100)
                self.progress_signal.emit(progress)

                # # –£–¥–∞–ª—è–µ–º –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
                # company_name = self.remove_geo_mentions(company_name)
                # self.log("  ‚úì –£–¥–∞–ª–µ–Ω—ã –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è")

                # # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
                # company_name = self.clean_text(company_name)

                # result.append(company_name)
                # self.log(f"  ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {company_name[:60]}...")

                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å

            if not self._is_cancelled:
                duration = round(time.time() - self.convert_time_start, 2)

                self.log(f"\n{'='*60}")
                self.log(f"‚úÖ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total}")
                self.log(f"‚è± –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–Ω—è–ª–∞: {duration} —Å")
                self.log(f"{'='*60}\n")

                self.finished_signal.emit(result)
            # self.convert_time_end = time.time()
            # self.convert_time_result = round(self.convert_time_end - self.convert_time_start, 2)

            # self.finished_signal.emit(result)

        except Exception as e:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
            self.log(error_msg)
            # self.error_signal.emit(error_msg)

        finally:
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º LanguageTool
            self.close_tool()

    def close_tool(self):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ LanguageTool"""
        if self.tool:
            try:
                self.log("üîå –ó–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ LanguageTool...")
                self.tool.close()
                self.tool = None
                self.log("‚úÖ –ü—Ä–æ—Ü–µ—Å—Å Java –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
            except Exception as e:
                self.log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ LT: {e}")

    def log(self, message):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –ª–æ–≥–∞ –≤ UI"""
        self.log_signal.emit(message)

    def create_correct_spelling(self, word):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ —Å–ª–æ–≤–∞"""
        try:
            matches = self.tool.check(word)
            if matches:
                corrected_word = self.tool.correct(word)
            else:
                corrected_word = word

            self.log(f"  ‚úì –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: {word}")
            return corrected_word

        except Exception as e:
            self.log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ '{word}': {str(e)}")
            return word

    def remove_geo_mentions(self, text):
        """–£–¥–∞–ª–µ–Ω–∏–µ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        result_correct_text = self.geo_regex.sub('', text)

        return result_correct_text

    def standardize_names(self, text):
        """–ó–∞–º–µ–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –Ω–∞ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã"""
        # lower_text = text.lower()
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∑–∞–º–µ–Ω—ã –ø–æ –¥–ª–∏–Ω–µ (—Å–Ω–∞—á–∞–ª–∞ –¥–ª–∏–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã)
        sorted_replacements = sorted(self.replacements.items(), key=lambda x: len(x[0]), reverse=True)

        temp_text = text

        for long_name, short_name in sorted_replacements:
            pattern = re.compile(re.escape(long_name), re.IGNORECASE)
            if pattern.search(temp_text):
                temp_text = pattern.sub(short_name, temp_text)

        return temp_text

    def clean_formatting(self, text):
        """–ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ –ø—Ä–æ–±–µ–ª–æ–≤"""
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'\s+([.,;?!])', r'\1', text)
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
        text = re.sub(r'""+', '"', text)
        # –ü–µ—Ä–≤–∞—è –±—É–∫–≤–∞ –∑–∞–≥–ª–∞–≤–Ω–∞—è
        if text:
            text = text[0].upper() + text[1:]
        return text.strip()

    def check_and_correct(self, text):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ –≤—Å–µ–π —Å—Ç—Ä–æ–∫–∏ —Ü–µ–ª–∏–∫–æ–º"""
        try:
            matches = self.tool.check(text)
            if not matches:
                return text
            return language_tool_python.utils.correct(text, matches)
        except Exception:
            return text

    # def clean_text(self, text):
        # """–û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"""
        # # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞—Å—Ç–∏ –≤ –∫–∞–≤—ã—á–∫–∞—Ö
        # quoted_parts = re.findall(r'"(.*?)"', text)

        # temp_text = text
        # for part in quoted_parts:
        #     temp_text = re.sub(rf'"{re.escape(part)}"', "", temp_text)

        # # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª–æ–≤–∞ –≤–Ω–µ –∫–∞–≤—ã—á–µ–∫
        # words = temp_text.split()
        # corrected_words = []

        # for word in words:
        #     if word.isupper():
        #         corrected_words.append(word)
        #     else:
        #         corrected_words.append(word.lower())

        # cleaned_text = " ".join(corrected_words).strip()
        # if cleaned_text:
        #     cleaned_text = cleaned_text[0].upper() + cleaned_text[1:]

        # # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –Ω–∞ –º–µ—Å—Ç–æ
        # for part in quoted_parts:
        #     insert_pos = text.find(f'"{part}"')
        #     if insert_pos != -1:
        #         cleaned_text = (
        #             cleaned_text[:insert_pos] + f'"{part}"' + cleaned_text[insert_pos:]
        #         )

        # intermediate_result = cleaned_text

        # # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—é –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
        # words = intermediate_result.split()
        # corrected_words = []

        # self.log(f"  üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏–∏ ({len(words)} —Å–ª–æ–≤)...")

        # for idx, word in enumerate(words, 1):
        #     if self._is_cancelled:
        #         break

        #     corrected_word = self.create_correct_spelling(word)
        #     corrected_words.append(corrected_word)

        #     # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5 —Å–ª–æ–≤
        #     if idx % 5 == 0:
        #         self.log(f"  üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–ª–æ–≤: {idx}/{len(words)}")

        # cleaned_text = " ".join(corrected_words)
        # return cleaned_text
